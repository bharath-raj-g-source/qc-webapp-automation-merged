{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b858b26f-1156-47d8-8a1c-f874d7b6622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded data from 'Macro - BSA Market Duplicator 3.5-F1.xlsm'.\n",
      "Total number of rows in the 'Data Core' tab: 2997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths and names\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\" # Assuming the file has the .xlsm extension\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = \"data/\" + FILE_NAME # Assuming the file is in the 'data/' directory\n",
    "\n",
    "# 1. Load the DataFrame using the file path and sheet name\n",
    "# Pandas often uses the openpyxl engine by default, which can handle .xlsm files.\n",
    "try:\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=0  # Assuming the first row of 'Data Core' is the header\n",
    "    )\n",
    "\n",
    "    # 2. Get the count of rows\n",
    "    row_count = len(df_macro)\n",
    "\n",
    "    print(f\"✅ Successfully loaded data from '{FILE_NAME}'.\")\n",
    "    print(f\"Total number of rows in the '{SHEET_NAME}' tab: {row_count}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'. Please ensure the file name and path are correct.\")\n",
    "except ValueError as e:\n",
    "    # This error often occurs if the sheet name is wrong or the file is corrupted.\n",
    "    print(f\"❌ Error loading sheet '{SHEET_NAME}': {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7e3ddc-8acc-4598-9117-e3beb7993a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types of Loaded Columns ---\n",
      "Number                             float64\n",
      "Projects                            object\n",
      "Single Duplications per Project    float64\n",
      "Concatenate                        float64\n",
      "Concatenate 2                       object\n",
      "Orig Market                         object\n",
      "Orig Broadcaster                    object\n",
      "Orig Channel                        object\n",
      "Orig Channel ID                     object\n",
      "Dup Market                          object\n",
      "Dup Market ID                        int64\n",
      "Dup Broadcaster                     object\n",
      "Dup Channel                         object\n",
      "Dup Channel ID                      object\n",
      "Factor                             float64\n",
      "Time Diff. in Units                float64\n",
      "Concatenate 3                       object\n",
      "Concatenate 4                       object\n",
      "Unnamed: 18                        float64\n",
      "Loop Sequence                      float64\n",
      "Orig Market and Channel            float64\n",
      "Count of M/C per Loop Sequence     float64\n",
      "Unnamed: 22                        float64\n",
      "Project List                        object\n",
      "Unnamed: 24                        float64\n",
      "Single Duplication List            float64\n",
      "Z3:Z2                              float64\n",
      "Unnamed: 27                        float64\n",
      "dtype: object\n",
      "\n",
      "Total Rows Loaded: 2996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths and names\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 0 # Assuming the header detection (from previous turns) resulted in a specific index\n",
    "\n",
    "# --- NOTE: The actual header detection logic would run here to determine HEADER_INDEX ---\n",
    "# For this example, we assume the load parameters are finalized:\n",
    "HEADER_INDEX = 1 \n",
    "\n",
    "\n",
    "# 1. Load the DataFrame using the detected header row\n",
    "try:\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "\n",
    "    # 2. Clean column names (essential since you have 'Unnamed' and spaces)\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    # 3. Print the data types of all columns\n",
    "    print(\"\\n--- Data Types of Loaded Columns ---\")\n",
    "    print(df_macro.dtypes)\n",
    "    \n",
    "    print(f\"\\nTotal Rows Loaded: {len(df_macro)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6adb5004-e0c9-4ba6-89fe-96094dcf2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows where 'Projects' contains 'Formula 1': 141\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 1\n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "\n",
    "try:\n",
    "    # 1. Load data with correct header\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "    \n",
    "    # 2. Clean column names\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    # 3. Filter rows where 'Projects' column contains the search term (case-insensitive)\n",
    "    # The filter uses .astype(str) and na=False to safely handle potential NaN values.\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    count = len(filtered_df)\n",
    "\n",
    "    print(f\"Total rows where 'Projects' contains '{SEARCH_TERM}': {count}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Please ensure the file is in the correct path.\")\n",
    "except KeyError:\n",
    "    print(f\"Error: The 'Projects' column was not found. Please verify the header row index (currently set to {HEADER_INDEX}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6960aa94-3ee4-47d6-b3ce-c875eca99569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filtered rows ('Projects' containing 'Formula 1'): 141\n",
      "\n",
      "--- Summary of Duplication Logic ---\n",
      "A. Overall Unique Counts:\n",
      "   - Unique Orig Market: 10\n",
      "   - Unique Orig Channel: 76\n",
      "   - Unique Dup Market: 28\n",
      "   - Unique Dup Channel: 84\n",
      "\n",
      "B. Duplication Fan-Out (Unique Targets per Origin):\n",
      "| Orig Market    |   Unique Dup Market Count |   Unique Dup Channel Count |\n",
      "|:---------------|--------------------------:|---------------------------:|\n",
      "| ARGENTINA      |                        16 |                         10 |\n",
      "| GERMANY        |                         4 |                          3 |\n",
      "| PERU           |                         4 |                          9 |\n",
      "| COLOMBIA       |                         2 |                          7 |\n",
      "| PAN-BALTIC     |                         2 |                          1 |\n",
      "| FRANCE         |                         1 |                          8 |\n",
      "| MEXICO         |                         1 |                          4 |\n",
      "| JAPAN          |                         1 |                          1 |\n",
      "| SOUTH AFRICA   |                         1 |                         31 |\n",
      "| UNITED KINGDOM |                         1 |                         12 |\n",
      "\n",
      "C. Channel Overlap Analysis:\n",
      "   - Channels that are BOTH an origin and a duplication target: 42\n",
      "   - Example Overlap Channels (Top 5): ['CANAL+ FOOT (FRA)', 'CANAL+ FORMULA 1 (FRA)', 'CANAL+ FRANCE (FRA)', 'CANAL+ LIVE 1 (FRA)', 'CANAL+ PREMIER LEAGUE (FRA)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "KEY_COLS = [\"Orig Market\", \"Orig Channel\", \"Dup Market\", \"Dup Channel\"]\n",
    "\n",
    "try:\n",
    "    # 1. Load and Filter Data\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    initial_count = len(filtered_df)\n",
    "\n",
    "    # 2. Data Cleaning and Preparation for Analysis\n",
    "    analysis_df = filtered_df[KEY_COLS].copy()\n",
    "    \n",
    "    # Ensure all key columns are clean strings (strip, upper case)\n",
    "    for col in KEY_COLS:\n",
    "        analysis_df[col] = analysis_df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # 3. Calculate Overall Unique Counts\n",
    "    unique_counts = analysis_df[KEY_COLS].nunique().to_dict()\n",
    "\n",
    "    # 4. Calculate Duplication Relationships per Orig Market\n",
    "    \n",
    "    # Unique Dup Markets per Orig Market\n",
    "    dup_market_summary = analysis_df.groupby('Orig Market')['Dup Market'].nunique().sort_values(ascending=False).to_frame(name='Unique Dup Market Count')\n",
    "\n",
    "    # Unique Dup Channels per Orig Market\n",
    "    dup_channel_summary = analysis_df.groupby('Orig Market')['Dup Channel'].nunique().to_frame(name='Unique Dup Channel Count')\n",
    "\n",
    "    # 5. Calculate Channel Overlap\n",
    "    orig_channels_set = set(analysis_df['Orig Channel'].unique())\n",
    "    dup_channels_set = set(analysis_df['Dup Channel'].unique())\n",
    "    \n",
    "    # Channels that exist as BOTH source (Orig) and target (Dup)\n",
    "    overlap_channels = orig_channels_set.intersection(dup_channels_set)\n",
    "    \n",
    "    # 6. Print Summary Results\n",
    "    print(f\"Total filtered rows ('Projects' containing '{SEARCH_TERM}'): {initial_count}\")\n",
    "    print(\"\\n--- Summary of Duplication Logic ---\")\n",
    "    \n",
    "    # Print Unique Counts\n",
    "    print(\"A. Overall Unique Counts:\")\n",
    "    for key, count in unique_counts.items():\n",
    "        print(f\"   - Unique {key}: {count}\")\n",
    "\n",
    "    print(\"\\nB. Duplication Fan-Out (Unique Targets per Origin):\")\n",
    "    \n",
    "    # Join summaries for a combined view\n",
    "    combined_summary = dup_market_summary.join(dup_channel_summary)\n",
    "    print(combined_summary.to_markdown())\n",
    "\n",
    "    print(\"\\nC. Channel Overlap Analysis:\")\n",
    "    print(f\"   - Channels that are BOTH an origin and a duplication target: {len(overlap_channels)}\")\n",
    "    print(f\"   - Example Overlap Channels (Top 5): {sorted(list(overlap_channels))[:5]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'.\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Error: Required column not found: {e}. Please verify the header row index.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ae20a5-713e-440a-88fe-c1d59b9f3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filtered rows ('Projects' containing 'Formula 1'): 141\n",
      "\n",
      "--- Summary of Duplication Logic ---\n",
      "A. Overall Unique Counts:\n",
      "   - Unique Orig Market: 10\n",
      "   - Unique Orig Channel: 76\n",
      "   - Unique Dup Market: 28\n",
      "   - Unique Dup Channel: 84\n",
      "\n",
      "B. Duplication Fan-Out (Unique Targets per Origin):\n",
      "| Orig Market    |   Unique Dup Market Count |   Unique Dup Channel Count |\n",
      "|:---------------|--------------------------:|---------------------------:|\n",
      "| ARGENTINA      |                        16 |                         10 |\n",
      "| GERMANY        |                         4 |                          3 |\n",
      "| PERU           |                         4 |                          9 |\n",
      "| COLOMBIA       |                         2 |                          7 |\n",
      "| PAN-BALTIC     |                         2 |                          1 |\n",
      "| FRANCE         |                         1 |                          8 |\n",
      "| MEXICO         |                         1 |                          4 |\n",
      "| JAPAN          |                         1 |                          1 |\n",
      "| SOUTH AFRICA   |                         1 |                         31 |\n",
      "| UNITED KINGDOM |                         1 |                         12 |\n",
      "\n",
      "D. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\n",
      "| Orig Market    | Associated Dup Markets List                                                                                                                                                                          |\n",
      "|:---------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| ARGENTINA      | ['BOLIVIA', 'CHILE', 'COLOMBIA', 'COSTA RICA', 'DOMINICAN REPUBLIC', 'ECUADOR', 'EL SALVADOR', 'GUATEMALA', 'HONDURAS', 'MEXICO', 'NICARAGUA', 'PANAMA', 'PARAGUAY', 'PERU', 'URUGUAY', 'VENEZUELA'] |\n",
      "| COLOMBIA       | ['ECUADOR', 'VENEZUELA']                                                                                                                                                                             |\n",
      "| FRANCE         | ['MONACO']                                                                                                                                                                                           |\n",
      "| GERMANY        | ['AUSTRIA', 'LIECHTENSTEIN', 'LUXEMBOURG', 'SWITZERLAND']                                                                                                                                            |\n",
      "| JAPAN          | ['PAPUA NEW GUINEA']                                                                                                                                                                                 |\n",
      "| MEXICO         | ['PAN-CENTRAL AMERICA']                                                                                                                                                                              |\n",
      "| PAN-BALTIC     | ['ESTONIA', 'LITHUANIA']                                                                                                                                                                             |\n",
      "| PERU           | ['BOLIVIA', 'PAN-CARIBBEAN', 'PARAGUAY', 'URUGUAY']                                                                                                                                                  |\n",
      "| SOUTH AFRICA   | ['PAN-AFRICA']                                                                                                                                                                                       |\n",
      "| UNITED KINGDOM | ['IRELAND']                                                                                                                                                                                          |\n",
      "\n",
      "C. Channel Overlap Analysis:\n",
      "   - Channels that are BOTH an origin and a duplication target: 42\n",
      "   - Example Overlap Channels (Top 5): ['CANAL+ FOOT (FRA)', 'CANAL+ FORMULA 1 (FRA)', 'CANAL+ FRANCE (FRA)', 'CANAL+ LIVE 1 (FRA)', 'CANAL+ PREMIER LEAGUE (FRA)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "KEY_COLS = [\"Orig Market\", \"Orig Channel\", \"Dup Market\", \"Dup Channel\"]\n",
    "\n",
    "try:\n",
    "    # 1. Load and Filter Data\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    initial_count = len(filtered_df)\n",
    "\n",
    "    # 2. Data Cleaning and Preparation for Analysis\n",
    "    analysis_df = filtered_df[KEY_COLS].copy()\n",
    "    \n",
    "    # Ensure all key columns are clean strings (strip, upper case)\n",
    "    for col in KEY_COLS:\n",
    "        analysis_df[col] = analysis_df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # 3. Calculate Overall Unique Counts\n",
    "    unique_counts = analysis_df[KEY_COLS].nunique().to_dict()\n",
    "\n",
    "    # 4. Calculate Duplication Relationships per Orig Market\n",
    "    \n",
    "    # Unique Dup Markets per Orig Market (for the combined table)\n",
    "    dup_market_summary = analysis_df.groupby('Orig Market')['Dup Market'].nunique().sort_values(ascending=False).to_frame(name='Unique Dup Market Count')\n",
    "\n",
    "    # Unique Dup Channels per Orig Market\n",
    "    dup_channel_summary = analysis_df.groupby('Orig Market')['Dup Channel'].nunique().to_frame(name='Unique Dup Channel Count')\n",
    "\n",
    "    # 4a. NEW: Calculate the List of Dup Markets associated with each Orig Market\n",
    "    dup_market_list_summary = analysis_df.groupby('Orig Market')['Dup Market'].apply(\n",
    "        lambda x: sorted(x.unique())\n",
    "    ).to_frame(name='Associated Dup Markets List')\n",
    "\n",
    "\n",
    "    # 5. Calculate Channel Overlap\n",
    "    orig_channels_set = set(analysis_df['Orig Channel'].unique())\n",
    "    dup_channels_set = set(analysis_df['Dup Channel'].unique())\n",
    "    \n",
    "    # Channels that exist as BOTH source (Orig) and target (Dup)\n",
    "    overlap_channels = orig_channels_set.intersection(dup_channels_set)\n",
    "    \n",
    "    # 6. Print Summary Results\n",
    "    print(f\"Total filtered rows ('Projects' containing '{SEARCH_TERM}'): {initial_count}\")\n",
    "    print(\"\\n--- Summary of Duplication Logic ---\")\n",
    "    \n",
    "    # Print Unique Counts\n",
    "    print(\"A. Overall Unique Counts:\")\n",
    "    for key, count in unique_counts.items():\n",
    "        print(f\"   - Unique {key}: {count}\")\n",
    "\n",
    "    print(\"\\nB. Duplication Fan-Out (Unique Targets per Origin):\")\n",
    "    \n",
    "    # Join summaries for a combined view\n",
    "    combined_summary = dup_market_summary.join(dup_channel_summary)\n",
    "    print(combined_summary.to_markdown())\n",
    "\n",
    "    # D. Detailed Dup Market List (NEW SECTION)\n",
    "    print(\"\\nD. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\")\n",
    "    print(dup_market_list_summary.to_markdown(stralign='left'))\n",
    "\n",
    "\n",
    "    print(\"\\nC. Channel Overlap Analysis:\")\n",
    "    print(f\"   - Channels that are BOTH an origin and a duplication target: {len(overlap_channels)}\")\n",
    "    print(f\"   - Example Overlap Channels (Top 5): {sorted(list(overlap_channels))[:5]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'.\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Error: Required column not found: {e}. Please verify the header row index.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed920e9-3709-4c4c-b16b-1046b2b9d537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e71d1-47d5-4233-81ca-a6501f61beb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf5b57-8617-4b93-8591-2590c3e14909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb34350a-0ef6-49f6-bc70-5c518c9c3ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filtered rows ('Projects' containing 'Formula 1'): 141\n",
      "\n",
      "--- Summary of Duplication Logic ---\n",
      "A. Overall Unique Counts:\n",
      "   - Unique Orig Market: 10\n",
      "   - Unique Orig Channel: 76\n",
      "   - Unique Dup Market: 28\n",
      "   - Unique Dup Channel: 84\n",
      "\n",
      "B. Duplication Fan-Out (Unique Targets per Origin):\n",
      "| Orig Market    |   Unique Dup Market Count |   Unique Dup Channel Count |   Identical Channel Rules Count |\n",
      "|:---------------|--------------------------:|---------------------------:|--------------------------------:|\n",
      "| ARGENTINA      |                        16 |                         10 |                               0 |\n",
      "| GERMANY        |                         4 |                          3 |                              12 |\n",
      "| PERU           |                         4 |                          9 |                              36 |\n",
      "| COLOMBIA       |                         2 |                          7 |                              14 |\n",
      "| PAN-BALTIC     |                         2 |                          1 |                               2 |\n",
      "| FRANCE         |                         1 |                          8 |                               9 |\n",
      "| MEXICO         |                         1 |                          4 |                               0 |\n",
      "| JAPAN          |                         1 |                          1 |                               1 |\n",
      "| SOUTH AFRICA   |                         1 |                         31 |                               2 |\n",
      "| UNITED KINGDOM |                         1 |                         12 |                              14 |\n",
      "\n",
      "D. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\n",
      "| Orig Market    | Associated Dup Markets List                                                                                                                                                                          |\n",
      "|:---------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| ARGENTINA      | ['BOLIVIA', 'CHILE', 'COLOMBIA', 'COSTA RICA', 'DOMINICAN REPUBLIC', 'ECUADOR', 'EL SALVADOR', 'GUATEMALA', 'HONDURAS', 'MEXICO', 'NICARAGUA', 'PANAMA', 'PARAGUAY', 'PERU', 'URUGUAY', 'VENEZUELA'] |\n",
      "| COLOMBIA       | ['ECUADOR', 'VENEZUELA']                                                                                                                                                                             |\n",
      "| FRANCE         | ['MONACO']                                                                                                                                                                                           |\n",
      "| GERMANY        | ['AUSTRIA', 'LIECHTENSTEIN', 'LUXEMBOURG', 'SWITZERLAND']                                                                                                                                            |\n",
      "| JAPAN          | ['PAPUA NEW GUINEA']                                                                                                                                                                                 |\n",
      "| MEXICO         | ['PAN-CENTRAL AMERICA']                                                                                                                                                                              |\n",
      "| PAN-BALTIC     | ['ESTONIA', 'LITHUANIA']                                                                                                                                                                             |\n",
      "| PERU           | ['BOLIVIA', 'PAN-CARIBBEAN', 'PARAGUAY', 'URUGUAY']                                                                                                                                                  |\n",
      "| SOUTH AFRICA   | ['PAN-AFRICA']                                                                                                                                                                                       |\n",
      "| UNITED KINGDOM | ['IRELAND']                                                                                                                                                                                          |\n",
      "\n",
      "C. Channel Overlap Analysis (Global):\n",
      "   - Channels that are BOTH an origin and a duplication target: 42\n",
      "   - Example Overlap Channels (Top 5): ['CANAL+ FOOT (FRA)', 'CANAL+ FORMULA 1 (FRA)', 'CANAL+ FRANCE (FRA)', 'CANAL+ LIVE 1 (FRA)', 'CANAL+ PREMIER LEAGUE (FRA)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "KEY_COLS = [\"Orig Market\", \"Orig Channel\", \"Dup Market\", \"Dup Channel\"]\n",
    "\n",
    "try:\n",
    "    # 1. Load and Filter Data\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    initial_count = len(filtered_df)\n",
    "\n",
    "    # 2. Data Cleaning and Preparation for Analysis\n",
    "    analysis_df = filtered_df[KEY_COLS].copy()\n",
    "    \n",
    "    # Ensure all key columns are clean strings (strip, upper case)\n",
    "    for col in KEY_COLS:\n",
    "        analysis_df[col] = analysis_df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # 3. Calculate Overall Unique Counts\n",
    "    unique_counts = analysis_df[KEY_COLS].nunique().to_dict()\n",
    "\n",
    "    # 4. Calculate Duplication Relationships per Orig Market\n",
    "    \n",
    "    # Unique Dup Markets per Orig Market (for the combined table)\n",
    "    dup_market_summary = analysis_df.groupby('Orig Market')['Dup Market'].nunique().sort_values(ascending=False).to_frame(name='Unique Dup Market Count')\n",
    "\n",
    "    # Unique Dup Channels per Orig Market\n",
    "    dup_channel_summary = analysis_df.groupby('Orig Market')['Dup Channel'].nunique().to_frame(name='Unique Dup Channel Count')\n",
    "\n",
    "    # 4a. List of Dup Markets associated with each Orig Market\n",
    "    dup_market_list_summary = analysis_df.groupby('Orig Market')['Dup Market'].apply(\n",
    "        lambda x: sorted(x.unique())\n",
    "    ).to_frame(name='Associated Dup Markets List')\n",
    "    \n",
    "    # --- NEW DETAILED CHANNEL OVERLAP ANALYSIS ---\n",
    "    \n",
    "    # Calculate a boolean mask indicating if the Orig Channel name is IDENTICAL to the Dup Channel name\n",
    "    # We group by the specific rule pair (Orig Market, Dup Market) and check if the channels are the same.\n",
    "    \n",
    "    # Note: Since the core duplication rule is applied row-by-row, we check if the channels match on that row.\n",
    "    channel_match_rules = analysis_df[analysis_df['Orig Channel'] == analysis_df['Dup Channel']]\n",
    "    \n",
    "    # Count how many unique pairs (Orig Market, Dup Market) had this channel match\n",
    "    matched_channel_rules_count = channel_match_rules.groupby('Orig Market').size().to_frame(name='Rules with Same Orig/Dup Channel')\n",
    "\n",
    "\n",
    "    # 5. Calculate Global Channel Overlap (Old Step 5)\n",
    "    orig_channels_set = set(analysis_df['Orig Channel'].unique())\n",
    "    dup_channels_set = set(analysis_df['Dup Channel'].unique())\n",
    "    overlap_channels = orig_channels_set.intersection(dup_channels_set)\n",
    "    \n",
    "    # 6. Print Summary Results\n",
    "    print(f\"Total filtered rows ('Projects' containing '{SEARCH_TERM}'): {initial_count}\")\n",
    "    print(\"\\n--- Summary of Duplication Logic ---\")\n",
    "    \n",
    "    # Print Unique Counts\n",
    "    print(\"A. Overall Unique Counts:\")\n",
    "    for key, count in unique_counts.items():\n",
    "        print(f\"   - Unique {key}: {count}\")\n",
    "\n",
    "    print(\"\\nB. Duplication Fan-Out (Unique Targets per Origin):\")\n",
    "    \n",
    "    # Join summaries for a combined view\n",
    "    # Fill NaN with 0 for markets that had no channel similarity\n",
    "    combined_summary = dup_market_summary.join(dup_channel_summary).join(matched_channel_rules_count).fillna(0)\n",
    "    \n",
    "    # Rename the new column for clarity\n",
    "    combined_summary = combined_summary.rename(columns={'Rules with Same Orig/Dup Channel': 'Identical Channel Rules Count'})\n",
    "    \n",
    "    print(combined_summary.to_markdown())\n",
    "\n",
    "    print(\"\\nD. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\")\n",
    "    print(dup_market_list_summary.to_markdown(stralign='left'))\n",
    "\n",
    "\n",
    "    print(\"\\nC. Channel Overlap Analysis (Global):\")\n",
    "    print(f\"   - Channels that are BOTH an origin and a duplication target: {len(overlap_channels)}\")\n",
    "    print(f\"   - Example Overlap Channels (Top 5): {sorted(list(overlap_channels))[:5]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'.\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Error: Required column not found: {e}. Please verify the header row index.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8de9ebd-2b26-4eb2-95d6-4ea8e5a77234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filtered rows ('Projects' containing 'Formula 1'): 141\n",
      "\n",
      "--- Summary of Duplication Logic ---\n",
      "A. Overall Unique Counts:\n",
      "   - Unique Orig Market: 10\n",
      "   - Unique Orig Channel: 76\n",
      "   - Unique Dup Market: 28\n",
      "   - Unique Dup Channel: 84\n",
      "\n",
      "B. Duplication Fan-Out (Unique Targets per Origin):\n",
      "| Orig Market    |   Unique Dup Market Count |   Unique Orig Channel Count |   Unique Dup Channel Count |   Identical Channel Rules Count |\n",
      "|:---------------|--------------------------:|----------------------------:|---------------------------:|--------------------------------:|\n",
      "| ARGENTINA      |                        16 |                           1 |                         10 |                               0 |\n",
      "| GERMANY        |                         4 |                           3 |                          3 |                              12 |\n",
      "| PERU           |                         4 |                           9 |                          9 |                              36 |\n",
      "| COLOMBIA       |                         2 |                           7 |                          7 |                              14 |\n",
      "| PAN-BALTIC     |                         2 |                           1 |                          1 |                               2 |\n",
      "| FRANCE         |                         1 |                           7 |                          8 |                               9 |\n",
      "| MEXICO         |                         1 |                           4 |                          4 |                               0 |\n",
      "| JAPAN          |                         1 |                           1 |                          1 |                               1 |\n",
      "| SOUTH AFRICA   |                         1 |                          31 |                         31 |                               2 |\n",
      "| UNITED KINGDOM |                         1 |                          12 |                         12 |                              14 |\n",
      "\n",
      "D. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\n",
      "| Orig Market    | Associated Dup Markets List                                                                                                                                                                          |\n",
      "|:---------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| ARGENTINA      | ['BOLIVIA', 'CHILE', 'COLOMBIA', 'COSTA RICA', 'DOMINICAN REPUBLIC', 'ECUADOR', 'EL SALVADOR', 'GUATEMALA', 'HONDURAS', 'MEXICO', 'NICARAGUA', 'PANAMA', 'PARAGUAY', 'PERU', 'URUGUAY', 'VENEZUELA'] |\n",
      "| COLOMBIA       | ['ECUADOR', 'VENEZUELA']                                                                                                                                                                             |\n",
      "| FRANCE         | ['MONACO']                                                                                                                                                                                           |\n",
      "| GERMANY        | ['AUSTRIA', 'LIECHTENSTEIN', 'LUXEMBOURG', 'SWITZERLAND']                                                                                                                                            |\n",
      "| JAPAN          | ['PAPUA NEW GUINEA']                                                                                                                                                                                 |\n",
      "| MEXICO         | ['PAN-CENTRAL AMERICA']                                                                                                                                                                              |\n",
      "| PAN-BALTIC     | ['ESTONIA', 'LITHUANIA']                                                                                                                                                                             |\n",
      "| PERU           | ['BOLIVIA', 'PAN-CARIBBEAN', 'PARAGUAY', 'URUGUAY']                                                                                                                                                  |\n",
      "| SOUTH AFRICA   | ['PAN-AFRICA']                                                                                                                                                                                       |\n",
      "| UNITED KINGDOM | ['IRELAND']                                                                                                                                                                                          |\n",
      "\n",
      "C. Channel Overlap Analysis (Global):\n",
      "   - Channels that are BOTH an origin and a duplication target: 42\n",
      "   - Example Overlap Channels (Top 5): ['CANAL+ FOOT (FRA)', 'CANAL+ FORMULA 1 (FRA)', 'CANAL+ FRANCE (FRA)', 'CANAL+ LIVE 1 (FRA)', 'CANAL+ PREMIER LEAGUE (FRA)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "KEY_COLS = [\"Orig Market\", \"Orig Channel\", \"Dup Market\", \"Dup Channel\"]\n",
    "\n",
    "try:\n",
    "    # 1. Load and Filter Data\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    initial_count = len(filtered_df)\n",
    "\n",
    "    # 2. Data Cleaning and Preparation for Analysis\n",
    "    analysis_df = filtered_df[KEY_COLS].copy()\n",
    "    \n",
    "    # Ensure all key columns are clean strings (strip, upper case)\n",
    "    for col in KEY_COLS:\n",
    "        analysis_df[col] = analysis_df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # 3. Calculate Overall Unique Counts\n",
    "    unique_counts = analysis_df[KEY_COLS].nunique().to_dict()\n",
    "\n",
    "    # 4. Calculate Duplication Relationships per Orig Market\n",
    "    \n",
    "    # Unique Dup Markets per Orig Market\n",
    "    dup_market_summary = analysis_df.groupby('Orig Market')['Dup Market'].nunique().sort_values(ascending=False).to_frame(name='Unique Dup Market Count')\n",
    "\n",
    "    # Unique Dup Channels per Orig Market\n",
    "    dup_channel_summary = analysis_df.groupby('Orig Market')['Dup Channel'].nunique().to_frame(name='Unique Dup Channel Count')\n",
    "\n",
    "    # 4a. Unique Orig Channels per Orig Market (NEW METRIC)\n",
    "    orig_channel_summary = analysis_df.groupby('Orig Market')['Orig Channel'].nunique().to_frame(name='Unique Orig Channel Count')\n",
    "\n",
    "    # 4b. Detailed Dup Market List\n",
    "    dup_market_list_summary = analysis_df.groupby('Orig Market')['Dup Market'].apply(\n",
    "        lambda x: sorted(x.unique())\n",
    "    ).to_frame(name='Associated Dup Markets List')\n",
    "    \n",
    "    # --- DETAILED CHANNEL OVERLAP ANALYSIS ---\n",
    "    channel_match_rules = analysis_df[analysis_df['Orig Channel'] == analysis_df['Dup Channel']]\n",
    "    matched_channel_rules_count = channel_match_rules.groupby('Orig Market').size().to_frame(name='Identical Channel Rules Count').fillna(0)\n",
    "\n",
    "    # 5. Calculate Global Channel Overlap\n",
    "    orig_channels_set = set(analysis_df['Orig Channel'].unique())\n",
    "    dup_channels_set = set(analysis_df['Dup Channel'].unique())\n",
    "    overlap_channels = orig_channels_set.intersection(dup_channels_set)\n",
    "    \n",
    "    # 6. Print Summary Results\n",
    "    print(f\"Total filtered rows ('Projects' containing '{SEARCH_TERM}'): {initial_count}\")\n",
    "    print(\"\\n--- Summary of Duplication Logic ---\")\n",
    "    \n",
    "    # Print Unique Counts\n",
    "    print(\"A. Overall Unique Counts:\")\n",
    "    for key, count in unique_counts.items():\n",
    "        print(f\"   - Unique {key}: {count}\")\n",
    "\n",
    "    print(\"\\nB. Duplication Fan-Out (Unique Targets per Origin):\")\n",
    "    \n",
    "    # Join all summaries for the combined view\n",
    "    combined_summary = dup_market_summary \\\n",
    "        .join(orig_channel_summary) \\\n",
    "        .join(dup_channel_summary) \\\n",
    "        .join(matched_channel_rules_count).fillna(0)\n",
    "    \n",
    "    # Ensure the Identical Channel Rules Count is properly joined/handled before print\n",
    "    # Final cleanup of the table to ensure all metrics are integers\n",
    "    combined_summary = combined_summary.astype(int)\n",
    "    \n",
    "    print(combined_summary.to_markdown())\n",
    "\n",
    "    print(\"\\nD. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\")\n",
    "    print(dup_market_list_summary.to_markdown(stralign='left'))\n",
    "\n",
    "\n",
    "    print(\"\\nC. Channel Overlap Analysis (Global):\")\n",
    "    print(f\"   - Channels that are BOTH an origin and a duplication target: {len(overlap_channels)}\")\n",
    "    print(f\"   - Example Overlap Channels (Top 5): {sorted(list(overlap_channels))[:5]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'.\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Error: Required column not found: {e}. Please verify the header row index.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d7986-5f01-4e54-9ad4-dfe1ae75e761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad0e33-5d4d-4b87-96c5-236af56332cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3328c75-2e99-46bd-86cd-6b49ccb4380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filtered rows ('Projects' containing 'Formula 1'): 141\n",
      "\n",
      "--- Summary of Duplication Logic ---\n",
      "A. Overall Unique Counts:\n",
      "   - Unique Orig Market: 10\n",
      "   - Unique Orig Channel: 76\n",
      "   - Unique Dup Market: 28\n",
      "   - Unique Dup Channel: 84\n",
      "\n",
      "B. Duplication Fan-Out (Unique Targets per Origin):\n",
      "| Orig Market    |   Unique Dup Market Count |   Unique Orig Channel Count |   Unique Dup Channel Count |   Similar Channel Rules Count (Normalized) |\n",
      "|:---------------|--------------------------:|----------------------------:|---------------------------:|-------------------------------------------:|\n",
      "| ARGENTINA      |                        16 |                           1 |                         10 |                                         16 |\n",
      "| GERMANY        |                         4 |                           3 |                          3 |                                         12 |\n",
      "| PERU           |                         4 |                           9 |                          9 |                                         36 |\n",
      "| COLOMBIA       |                         2 |                           7 |                          7 |                                         14 |\n",
      "| PAN-BALTIC     |                         2 |                           1 |                          1 |                                          2 |\n",
      "| FRANCE         |                         1 |                           7 |                          8 |                                         10 |\n",
      "| MEXICO         |                         1 |                           4 |                          4 |                                          4 |\n",
      "| JAPAN          |                         1 |                           1 |                          1 |                                          1 |\n",
      "| SOUTH AFRICA   |                         1 |                          31 |                         31 |                                         31 |\n",
      "| UNITED KINGDOM |                         1 |                          12 |                         12 |                                         15 |\n",
      "\n",
      "D. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\n",
      "| Orig Market    | Associated Dup Markets List                                                                                                                                                                          |\n",
      "|:---------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| ARGENTINA      | ['BOLIVIA', 'CHILE', 'COLOMBIA', 'COSTA RICA', 'DOMINICAN REPUBLIC', 'ECUADOR', 'EL SALVADOR', 'GUATEMALA', 'HONDURAS', 'MEXICO', 'NICARAGUA', 'PANAMA', 'PARAGUAY', 'PERU', 'URUGUAY', 'VENEZUELA'] |\n",
      "| COLOMBIA       | ['ECUADOR', 'VENEZUELA']                                                                                                                                                                             |\n",
      "| FRANCE         | ['MONACO']                                                                                                                                                                                           |\n",
      "| GERMANY        | ['AUSTRIA', 'LIECHTENSTEIN', 'LUXEMBOURG', 'SWITZERLAND']                                                                                                                                            |\n",
      "| JAPAN          | ['PAPUA NEW GUINEA']                                                                                                                                                                                 |\n",
      "| MEXICO         | ['PAN-CENTRAL AMERICA']                                                                                                                                                                              |\n",
      "| PAN-BALTIC     | ['ESTONIA', 'LITHUANIA']                                                                                                                                                                             |\n",
      "| PERU           | ['BOLIVIA', 'PAN-CARIBBEAN', 'PARAGUAY', 'URUGUAY']                                                                                                                                                  |\n",
      "| SOUTH AFRICA   | ['PAN-AFRICA']                                                                                                                                                                                       |\n",
      "| UNITED KINGDOM | ['IRELAND']                                                                                                                                                                                          |\n",
      "\n",
      "C. Channel Overlap Analysis (Global):\n",
      "   - Channels that are BOTH an origin and a duplication target: 42\n",
      "   - Example Overlap Channels (Top 5): ['CANAL+ FOOT (FRA)', 'CANAL+ FORMULA 1 (FRA)', 'CANAL+ FRANCE (FRA)', 'CANAL+ LIVE 1 (FRA)', 'CANAL+ PREMIER LEAGUE (FRA)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re # Needed for regex in normalization\n",
    "\n",
    "FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "SHEET_NAME = \"Data Core\"\n",
    "FILE_PATH = os.path.join(\"data\", FILE_NAME) \n",
    "HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "KEY_COLS = [\"Orig Market\", \"Orig Channel\", \"Dup Market\", \"Dup Channel\"]\n",
    "\n",
    "# --- NEW HELPER FUNCTION FOR CHANNEL NAME NORMALIZATION ---\n",
    "def normalize_channel_name(channel_series):\n",
    "    \"\"\"\n",
    "    Removes country codes, parentheses, and extra spaces to compare channel names \n",
    "    by their core identity (e.g., 'ESPN 4').\n",
    "    \"\"\"\n",
    "    # 1. Ensure string and convert to uppercase\n",
    "    normalized = channel_series.astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # 2. Remove anything inside parentheses (e.g., \"(ARG)\", \"(BOL)\")\n",
    "    normalized = normalized.str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "    \n",
    "    # 3. Remove known short country codes often following channel names\n",
    "    normalized = normalized.str.replace(r'\\s+ARG|\\s+BOL|\\s+CHL|\\s+PER|\\s+SWE|\\s+DE', '', regex=True)\n",
    "    \n",
    "    # 4. Remove 'TV' from channel names to group things like 'TV3'\n",
    "    normalized = normalized.str.replace(r'\\s+TV', '', regex=True)\n",
    "    \n",
    "    # 5. Final cleanup of extra spaces\n",
    "    normalized = normalized.str.strip()\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "try:\n",
    "    # 1. Load and Filter Data\n",
    "    df_macro = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_INDEX \n",
    "    )\n",
    "\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    initial_count = len(filtered_df)\n",
    "\n",
    "    # 2. Data Cleaning and Preparation for Analysis\n",
    "    analysis_df = filtered_df[KEY_COLS].copy()\n",
    "    \n",
    "    # Ensure all key columns are clean strings (strip, upper case)\n",
    "    for col in KEY_COLS:\n",
    "        analysis_df[col] = analysis_df[col].astype(str).str.strip().str.upper()\n",
    "        \n",
    "    # --- CRITICAL FIX: Add Normalized Channel Columns for Comparison ---\n",
    "    analysis_df['Orig Channel Norm'] = normalize_channel_name(analysis_df['Orig Channel'])\n",
    "    analysis_df['Dup Channel Norm'] = normalize_channel_name(analysis_df['Dup Channel'])\n",
    "\n",
    "\n",
    "    # 3. Calculate Overall Unique Counts (using raw data)\n",
    "    unique_counts = analysis_df[KEY_COLS].nunique().to_dict()\n",
    "\n",
    "    # 4. Calculate Duplication Relationships per Orig Market\n",
    "    \n",
    "    # Unique Dup Markets per Orig Market\n",
    "    dup_market_summary = analysis_df.groupby('Orig Market')['Dup Market'].nunique().sort_values(ascending=False).to_frame(name='Unique Dup Market Count')\n",
    "\n",
    "    # Unique Dup Channels per Orig Market\n",
    "    dup_channel_summary = analysis_df.groupby('Orig Market')['Dup Channel'].nunique().to_frame(name='Unique Dup Channel Count')\n",
    "\n",
    "    # Unique Orig Channels per Orig Market\n",
    "    orig_channel_summary = analysis_df.groupby('Orig Market')['Orig Channel'].nunique().to_frame(name='Unique Orig Channel Count')\n",
    "\n",
    "    # Detailed Dup Market List\n",
    "    dup_market_list_summary = analysis_df.groupby('Orig Market')['Dup Market'].apply(\n",
    "        lambda x: sorted(x.unique())\n",
    "    ).to_frame(name='Associated Dup Markets List')\n",
    "    \n",
    "    # --- DETAILED CHANNEL OVERLAP ANALYSIS (FIXED LOGIC) ---\n",
    "    # Count how many rules have the same CORE channel name (Normalized)\n",
    "    normalized_channel_match_rules = analysis_df[analysis_df['Orig Channel Norm'] == analysis_df['Dup Channel Norm']]\n",
    "    \n",
    "    # Aggregate the count of rules where the CORE channel name matched\n",
    "    matched_channel_rules_count = normalized_channel_match_rules.groupby('Orig Market').size().to_frame(name='Similar Channel Rules Count (Normalized)').fillna(0)\n",
    "    \n",
    "    # 5. Calculate Global Channel Overlap\n",
    "    orig_channels_set = set(analysis_df['Orig Channel'].unique())\n",
    "    dup_channels_set = set(analysis_df['Dup Channel'].unique())\n",
    "    overlap_channels = orig_channels_set.intersection(dup_channels_set)\n",
    "    \n",
    "    # 6. Print Summary Results\n",
    "    print(f\"Total filtered rows ('Projects' containing '{SEARCH_TERM}'): {initial_count}\")\n",
    "    print(\"\\n--- Summary of Duplication Logic ---\")\n",
    "    \n",
    "    # Print Unique Counts\n",
    "    print(\"A. Overall Unique Counts:\")\n",
    "    for key, count in unique_counts.items():\n",
    "        print(f\"   - Unique {key}: {count}\")\n",
    "\n",
    "    print(\"\\nB. Duplication Fan-Out (Unique Targets per Origin):\")\n",
    "    \n",
    "    # Join all summaries for the combined view\n",
    "    combined_summary = dup_market_summary \\\n",
    "        .join(orig_channel_summary) \\\n",
    "        .join(dup_channel_summary) \\\n",
    "        .join(matched_channel_rules_count).fillna(0).astype(int)\n",
    "    \n",
    "    print(combined_summary.to_markdown())\n",
    "\n",
    "    print(\"\\nD. Detailed Duplication Map (Orig Market -> Associated Dup Markets List):\")\n",
    "    print(dup_market_list_summary.to_markdown(stralign='left'))\n",
    "\n",
    "\n",
    "    print(\"\\nC. Channel Overlap Analysis (Global):\")\n",
    "    print(f\"   - Channels that are BOTH an origin and a duplication target: {len(overlap_channels)}\")\n",
    "    print(f\"   - Example Overlap Channels (Top 5): {sorted(list(overlap_channels))[:5]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at '{FILE_PATH}'.\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Error: Required column not found: {e}. Please verify the header row index.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97eb54e-b77f-4815-937e-290a81c8dd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad421e-c5bd-4bc3-a90b-4ed6c99246a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd8a6648-32b6-4240-a6c1-1d67bdb90920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region                                     object\n",
      "Market                                     object\n",
      "Market ID                                 float64\n",
      "Broadcaster                                object\n",
      "TV-Channel                                 object\n",
      "Channel ID                                float64\n",
      "Pay/Free TV                                object\n",
      "Date (UTC/GMT)                     datetime64[ns]\n",
      "Date                               datetime64[ns]\n",
      "Day                                        object\n",
      "Start (UTC)                                object\n",
      "End (UTC)                                  object\n",
      "Start                                      object\n",
      "End                                        object\n",
      "Duration                                   object\n",
      "Program Title                              object\n",
      "Program Description                        object\n",
      "Combined                                   object\n",
      "Type of program                            object\n",
      "Event                                      object\n",
      "Competition                                object\n",
      "Matchday                                   object\n",
      "Phase / Fixture / Episode Desc.            object\n",
      "Home Team                                 float64\n",
      "Vs                                        float64\n",
      "Away Team                                 float64\n",
      "Gender                                    float64\n",
      "Check                                     float64\n",
      "Aud. Estimates ['000s]                    float64\n",
      "TVR% 3+                                   float64\n",
      "Aud Metered (000s) 3+                     float64\n",
      "Share% 3+                                 float64\n",
      "TVR% 14+                                  float64\n",
      "Aud Metered (000s) 14+                    float64\n",
      "Share% 14+                                float64\n",
      "CPT's [Euro]                              float64\n",
      "Spot price in Euro [30 sec.]              float64\n",
      "Spot price in Euro [1 sec.]               float64\n",
      "Fixture analysis                          float64\n",
      "Brandbase upload                          float64\n",
      "Source                                     object\n",
      "BT Start                                  float64\n",
      "BT Duration                               float64\n",
      "Unnamed: 43                               float64\n",
      "Unnamed: 44                                object\n",
      "Unnamed: 45                                object\n",
      "Unnamed: 46                                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\n",
    "    \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "    sheet_name=\"Worksheet\",  # Specify the tab name\n",
    "    header=5 # \n",
    ")\n",
    "\n",
    "# print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "254369f6-c2ee-4379-b6ad-6d146ec9b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Duplication Channel Existence Check ---\n",
      "\n",
      "✅ CHECK RESULT:\n",
      "{'check_key': 'dup_channel_existence', 'status': 'Flagged', 'action': 'Duplication Channel Check', 'description': 'Checked 136 unique Dup Market/Channel requirements. Flagged 940 rows in markets missing required channels.', 'details': {'rows_flagged': 940, 'missing_requirements_count': 132, 'missing_channels_list': [{'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'ESPN Africa (AFR)', 'Normalized_Match_Key': 'ESPN AFRICA'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'ESPN 2 Africa (AFR)', 'Normalized_Match_Key': 'ESPN 2 AFRICA'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN (PER)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 2 (PER)', 'Normalized_Match_Key': 'ESPN 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 3 (PER)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 4 (PER)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'Fox Sports 2 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'Fox Sports 3 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN (PER)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 2 (PER)', 'Normalized_Match_Key': 'ESPN 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 3 (PER)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 4 (PER)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'Fox Sports 2 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'Fox Sports 3 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN (PER)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 2 (PER)', 'Normalized_Match_Key': 'ESPN 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 3 (PER)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 4 (PER)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'Fox Sports 2 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'Fox Sports 3 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 3'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN 4 (COL)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN (COL)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN 3 (COL)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN 4 (COL)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN (COL)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN 3 (COL)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'MEXICO', 'Dup_Market': 'PAN-CENTRAL AMERICA', 'Missing_Channel': 'ESPN (PCA)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'MEXICO', 'Dup_Market': 'PAN-CENTRAL AMERICA', 'Missing_Channel': 'ESPN 2 (PCA)', 'Normalized_Match_Key': 'ESPN 2'}, {'Orig_Market': 'MEXICO', 'Dup_Market': 'PAN-CENTRAL AMERICA', 'Missing_Channel': 'ESPN 3 (PCA)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 4 (BOL)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'CHILE', 'Missing_Channel': 'ESPN 4 (CHL)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'COLOMBIA', 'Missing_Channel': 'ESPN 4 (COL)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN 4 (ECU)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'MEXICO', 'Missing_Channel': 'ESPN 4 (MEX)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 4 (PAR)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'PERU', 'Missing_Channel': 'ESPN 4 (PER)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 4 (URY)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN 4 (VEN)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'COSTA RICA', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'DOMINICAN REPUBLIC', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'EL SALVADOR', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'GUATEMALA', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'HONDURAS', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'NICARAGUA', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'ARGENTINA', 'Dup_Market': 'PANAMA', 'Missing_Channel': 'ESPN 4 (C-AM)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN 5 (COL)', 'Normalized_Match_Key': 'ESPN 5'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN 6 (COL)', 'Normalized_Match_Key': 'ESPN 6'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'VENEZUELA', 'Missing_Channel': 'ESPN 7 (COL)', 'Normalized_Match_Key': 'ESPN 7'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN 5 (COL)', 'Normalized_Match_Key': 'ESPN 5'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN 6 (COL)', 'Normalized_Match_Key': 'ESPN 6'}, {'Orig_Market': 'COLOMBIA', 'Dup_Market': 'ECUADOR', 'Missing_Channel': 'ESPN 7 (COL)', 'Normalized_Match_Key': 'ESPN 7'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 5 (PER)', 'Normalized_Match_Key': 'ESPN 5'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 6 (PER)', 'Normalized_Match_Key': 'ESPN 6'}, {'Orig_Market': 'PERU', 'Dup_Market': 'URUGUAY', 'Missing_Channel': 'ESPN 7 (PER)', 'Normalized_Match_Key': 'ESPN 7'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 5 (PER)', 'Normalized_Match_Key': 'ESPN 5'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 6 (PER)', 'Normalized_Match_Key': 'ESPN 6'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PARAGUAY', 'Missing_Channel': 'ESPN 7 (PER)', 'Normalized_Match_Key': 'ESPN 7'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 5 (PER)', 'Normalized_Match_Key': 'ESPN 5'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 6 (PER)', 'Normalized_Match_Key': 'ESPN 6'}, {'Orig_Market': 'PERU', 'Dup_Market': 'BOLIVIA', 'Missing_Channel': 'ESPN 7 (PER)', 'Normalized_Match_Key': 'ESPN 7'}, {'Orig_Market': 'MEXICO', 'Dup_Market': 'PAN-CENTRAL AMERICA', 'Missing_Channel': 'ESPN 4 (PCA)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports+ (GBR)', 'Normalized_Match_Key': 'SKY SPORTS+'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'AUSTRIA', 'Missing_Channel': 'Sky Sport F1 DE', 'Normalized_Match_Key': 'SKY SPORT F1'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'LUXEMBOURG', 'Missing_Channel': 'Sky Sport F1 DE', 'Normalized_Match_Key': 'SKY SPORT F1'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'SWITZERLAND', 'Missing_Channel': 'Sky Sport F1 DE', 'Normalized_Match_Key': 'SKY SPORT F1'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'AUSTRIA', 'Missing_Channel': 'Sky Sport News DE', 'Normalized_Match_Key': 'SKY SPORT NEWS'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'LUXEMBOURG', 'Missing_Channel': 'Sky Sport News DE', 'Normalized_Match_Key': 'SKY SPORT NEWS'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'SWITZERLAND', 'Missing_Channel': 'Sky Sport News DE', 'Normalized_Match_Key': 'SKY SPORT NEWS'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'AUSTRIA', 'Missing_Channel': 'Sky Sport Top Event DE', 'Normalized_Match_Key': 'SKY SPORT TOP EVENT'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'LUXEMBOURG', 'Missing_Channel': 'Sky Sport Top Event DE', 'Normalized_Match_Key': 'SKY SPORT TOP EVENT'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'SWITZERLAND', 'Missing_Channel': 'Sky Sport Top Event DE', 'Normalized_Match_Key': 'SKY SPORT TOP EVENT'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 1 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 1'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 10 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 10'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 11 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 11'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 12 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 12'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 13 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 13'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 14 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 14'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 2 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 2'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 3 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 3'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 4 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 4'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 5 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 5'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 6 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 6'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 7 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 7'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 8 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 8'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport 9 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT 9'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Cricket (AFR)', 'Normalized_Match_Key': 'SUPERSPORT CRICKET'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Football (AFR)', 'Normalized_Match_Key': 'SUPERSPORT FOOTBALL'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Golf (AFR)', 'Normalized_Match_Key': 'SUPERSPORT GOLF'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Grandstand (AFR)', 'Normalized_Match_Key': 'SUPERSPORT GRANDSTAND'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport LaLiga (AFR)', 'Normalized_Match_Key': 'SUPERSPORT LALIGA'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Motorsport (AFR)', 'Normalized_Match_Key': 'SUPERSPORT MOTORSPORT'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Premier League (AFR)', 'Normalized_Match_Key': 'SUPERSPORT PREMIER LEAGUE'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Rugby (AFR)', 'Normalized_Match_Key': 'SUPERSPORT RUGBY'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Tennis (AFR)', 'Normalized_Match_Key': 'SUPERSPORT TENNIS'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Variety 1 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT VARIETY 1'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Variety 2 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT VARIETY 2'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Variety 3 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT VARIETY 3'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Variety 4 (AFR)', 'Normalized_Match_Key': 'SUPERSPORT VARIETY 4'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport WWE (AFR)', 'Normalized_Match_Key': 'SUPERSPORT WWE'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Cricket (GBR)', 'Normalized_Match_Key': 'SKY SPORTS CRICKET'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports F1 (GBR)', 'Normalized_Match_Key': 'SKY SPORTS F1'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Mix (GBR)', 'Normalized_Match_Key': 'SKY SPORTS MIX'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Red Button (GBR)', 'Normalized_Match_Key': 'SKY SPORTS RED BUTTON'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Action (GBR)', 'Normalized_Match_Key': 'SKY SPORTS ACTION'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Football (GBR)', 'Normalized_Match_Key': 'SKY SPORTS FOOTBALL'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Arena (GBR)', 'Normalized_Match_Key': 'SKY SPORTS ARENA'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Main Event (GBR)', 'Normalized_Match_Key': 'SKY SPORTS MAIN EVENT'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Sports Premier League (GBR)', 'Normalized_Match_Key': 'SKY SPORTS PREMIER LEAGUE'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Showcase +1 (GBR)', 'Normalized_Match_Key': 'SKY SHOWCASE +1'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Sport 360 (FRA)', 'Normalized_Match_Key': 'CANAL+ SPORT 360'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ France (FRA)', 'Normalized_Match_Key': 'CANAL+ FRANCE'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Sport (FRA)', 'Normalized_Match_Key': 'CANAL+ SPORT'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Live 1 (FRA)', 'Normalized_Match_Key': 'CANAL+ LIVE 1'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Foot (CHE)', 'Normalized_Match_Key': 'CANAL+ FOOT'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Foot (FRA)', 'Normalized_Match_Key': 'CANAL+ FOOT'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Formula 1 (FRA)', 'Normalized_Match_Key': 'CANAL+ FORMULA 1'}, {'Orig_Market': 'FRANCE', 'Dup_Market': 'MONACO', 'Missing_Channel': 'Canal+ Premier League (FRA)', 'Normalized_Match_Key': 'CANAL+ PREMIER LEAGUE'}, {'Orig_Market': 'JAPAN', 'Dup_Market': 'PAPUA NEW GUINEA', 'Missing_Channel': 'Fuji TV Next (JPN)', 'Normalized_Match_Key': 'FUJI NEXT'}, {'Orig_Market': 'SOUTH AFRICA', 'Dup_Market': 'PAN-AFRICA', 'Missing_Channel': 'SuperSport Maximo 1  (AFR)', 'Normalized_Match_Key': 'SUPERSPORT MAXIMO 1'}, {'Orig_Market': 'UNITED KINGDOM', 'Dup_Market': 'IRELAND', 'Missing_Channel': 'Sky Showcase (GBR)', 'Normalized_Match_Key': 'SKY SHOWCASE'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN 5 (PER)', 'Normalized_Match_Key': 'ESPN 5'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN 6 (PER)', 'Normalized_Match_Key': 'ESPN 6'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN 7 (PER)', 'Normalized_Match_Key': 'ESPN 7'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'Fox Sports 2 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'Fox Sports 3 (PER)', 'Normalized_Match_Key': 'FOX SPORTS 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN (PER)', 'Normalized_Match_Key': 'ESPN'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN 2 (PER)', 'Normalized_Match_Key': 'ESPN 2'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN 3 (PER)', 'Normalized_Match_Key': 'ESPN 3'}, {'Orig_Market': 'PERU', 'Dup_Market': 'PAN-CARIBBEAN', 'Missing_Channel': 'ESPN 4 (PER)', 'Normalized_Match_Key': 'ESPN 4'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'LIECHTENSTEIN', 'Missing_Channel': 'Sky Sport F1 DE', 'Normalized_Match_Key': 'SKY SPORT F1'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'LIECHTENSTEIN', 'Missing_Channel': 'Sky Sport News DE', 'Normalized_Match_Key': 'SKY SPORT NEWS'}, {'Orig_Market': 'GERMANY', 'Dup_Market': 'LIECHTENSTEIN', 'Missing_Channel': 'Sky Sport Top Event DE', 'Normalized_Match_Key': 'SKY SPORT TOP EVENT'}]}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, Any, List, Set\n",
    "\n",
    "# --- FILE PATHS AND CONSTANTS ---\n",
    "BSR_FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "BSR_SHEET_NAME = \"Worksheet\"\n",
    "BSR_HEADER_ROW = 5 \n",
    "\n",
    "MACRO_FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "MACRO_SHEET_NAME = \"Data Core\"\n",
    "MACRO_FILE_PATH = os.path.join(\"data\", MACRO_FILE_NAME) \n",
    "MACRO_HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "KEY_COLS = [\"Orig Market\", \"Dup Market\", \"Dup Channel\", \"Projects\", \"TV-Channel\", \"Market\"] \n",
    "REQUIRED_RULE_COLS = ['Orig Market', 'Dup Market', 'Dup Channel'] # Columns needed for validation logic\n",
    "\n",
    "# --- HELPER FUNCTION FOR CHANNEL NAME NORMALIZATION (MUST BE ACCESSIBLE) ---\n",
    "def normalize_channel_name(channel_series):\n",
    "    \"\"\"Removes country codes and parentheses to get core channel identity.\"\"\"\n",
    "    normalized = channel_series.astype(str).str.strip().str.upper()\n",
    "    normalized = normalized.str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+ARG|\\s+BOL|\\s+CHL|\\s+PER|\\s+SWE|\\s+DE', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+TV', '', regex=True)\n",
    "    return normalized.str.strip()\n",
    "\n",
    "# =========================================================================\n",
    "# === 1. DEFINITION OF THE VALIDATION FUNCTION (STANDALONE VERSION) =======\n",
    "# =========================================================================\n",
    "\n",
    "def validate_dup_channel_existence(df: pd.DataFrame, df_dup_rules: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Checks if every 'Dup Channel' required by the Duplication Rules is actually present \n",
    "    in the list of 'TV-Channel's within the corresponding 'Dup Market' of the BSR.\n",
    "    \n",
    "    Args:\n",
    "        df: The main BSR DataFrame.\n",
    "        df_dup_rules: Filtered DataFrame containing the duplication rules.\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    FLAG_COLUMN = 'QC_Dup_Channel_Existence_Flag'\n",
    "    \n",
    "    # 1. Initialization and Checks\n",
    "    df[FLAG_COLUMN] = 'OK'\n",
    "    REQUIRED_BSR_COLS = ['Market', 'TV-Channel']\n",
    "\n",
    "    if not all(col in df.columns for col in REQUIRED_BSR_COLS) or \\\n",
    "       not all(col in df_dup_rules.columns for col in REQUIRED_RULE_COLS):\n",
    "        return {\n",
    "            \"check_key\": \"dup_channel_existence\", \"status\": \"Skipped\",\n",
    "            \"action\": \"Duplication Channel Check\",\n",
    "            \"description\": \"Skipped: Missing required columns in BSR or Rule set.\",\n",
    "            \"details\": {\"rows_flagged\": 0}\n",
    "        }\n",
    "    \n",
    "    # 2. Data Preparation for Efficient Lookup\n",
    "    \n",
    "    # Standardize the BSR Market and Channel names (UPPER/Strip)\n",
    "    # We work on a copy of the BSR's key columns to avoid modifying the original DF unnecessarily during preparation\n",
    "    bsr_df_check = df[REQUIRED_BSR_COLS].copy()\n",
    "    bsr_df_check['Market_Norm'] = bsr_df_check['Market'].astype(str).str.strip().str.upper()\n",
    "    bsr_df_check['TV-Channel_Norm'] = bsr_df_check['TV-Channel'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Create a dictionary for quick lookup of existing channels in the BSR:\n",
    "    # Key: Dup Market Name (Normalized) -> Value: Set of existing TV-Channels (Normalized)\n",
    "    existing_channels_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].apply(set).to_dict()\n",
    "    \n",
    "    # 3. Iterate Through Duplication Rules and Validate\n",
    "    \n",
    "    missing_channels_log = []\n",
    "    \n",
    "    # Filter the rules and standardize keys for comparison\n",
    "    rules_to_check = df_dup_rules[REQUIRED_RULE_COLS].drop_duplicates().copy()\n",
    "    rules_to_check['Dup Market_Norm'] = rules_to_check['Dup Market'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # The required channel names must be normalized before validation!\n",
    "    rules_to_check['Required_Channel_Norm'] = normalize_channel_name(rules_to_check['Dup Channel']) \n",
    "    \n",
    "    rows_flagged = 0\n",
    "    \n",
    "    for index, rule in rules_to_check.iterrows():\n",
    "        dup_market = rule['Dup Market_Norm']\n",
    "        required_channel_norm = rule['Required_Channel_Norm']\n",
    "        orig_market = rule['Orig Market']\n",
    "        \n",
    "        # Look up the set of existing channels in the target Dup Market\n",
    "        existing_channels = existing_channels_map.get(dup_market, set())\n",
    "        \n",
    "        # 4. Validation Check: Does the required normalized channel exist in the target market's set?\n",
    "        if required_channel_norm not in existing_channels:\n",
    "            \n",
    "            # Log the specific failure reason\n",
    "            missing_channels_log.append({\n",
    "                \"Orig_Market\": orig_market,\n",
    "                \"Dup_Market\": rule['Dup Market'], \n",
    "                \"Missing_Channel\": rule['Dup Channel'], # Use raw channel name for reporting clarity\n",
    "                \"Normalized_Match_Key\": required_channel_norm\n",
    "            })\n",
    "            \n",
    "            # 5. Apply Flag to the BSR\n",
    "            # Flag ALL rows in the target Dup Market (since the issue is market-wide completeness)\n",
    "            flag_mask = (df['Market'].astype(str).str.strip().str.upper() == dup_market)\n",
    "            \n",
    "            flag_message = f\"Completeness Error: Missing required Dup Channel '{rule['Dup Channel']}' (Source: {orig_market}).\"\n",
    "            \n",
    "            # Only flag rows that were not already flagged for a similar or harder error\n",
    "            current_flags = df.loc[flag_mask, FLAG_COLUMN]\n",
    "            rows_to_flag = flag_mask & (current_flags == 'OK')\n",
    "            \n",
    "            df.loc[rows_to_flag, FLAG_COLUMN] = flag_message\n",
    "            rows_flagged += rows_to_flag.sum()\n",
    "\n",
    "\n",
    "    final_status = \"Completed\" if rows_flagged == 0 else \"Flagged\"\n",
    "\n",
    "    return {\n",
    "        \"check_key\": \"dup_channel_existence\",\n",
    "        \"status\": final_status,\n",
    "        \"action\": \"Duplication Channel Check\",\n",
    "        \"description\": f\"Checked {len(rules_to_check)} unique Dup Market/Channel requirements. Flagged {rows_flagged} rows in markets missing required channels.\",\n",
    "        \"details\": {\n",
    "            \"rows_flagged\": int(rows_flagged),\n",
    "            \"missing_requirements_count\": len(missing_channels_log),\n",
    "            \"missing_channels_list\": missing_channels_log\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# =========================================================================\n",
    "# === 2. EXECUTION IN JUPYTER NOTEBOOK (USING GLOBAL SCOPE) ===============\n",
    "# =========================================================================\n",
    "\n",
    "print(\"--- Starting Duplication Channel Existence Check ---\")\n",
    "\n",
    "try:\n",
    "    # 1. LOAD BSR DATA\n",
    "    df_bsr = pd.read_excel(BSR_FILE_PATH, sheet_name=BSR_SHEET_NAME, header=BSR_HEADER_ROW)\n",
    "    df_bsr.columns = [str(c).strip() for c in df_bsr.columns]\n",
    "\n",
    "    # 2. LOAD AND FILTER MACRO DATA (Your Duplication Rules)\n",
    "    df_macro = pd.read_excel(MACRO_FILE_PATH, sheet_name=MACRO_SHEET_NAME, header=MACRO_HEADER_INDEX)\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    # 3. Prepare Rule DataFrame (analysis_df / DF_DUP_RULES)\n",
    "    analysis_df = filtered_df[REQUIRED_RULE_COLS].copy()\n",
    "    \n",
    "    # Normalize Market names in the Rule sheet (REQUIRED for checking)\n",
    "    analysis_df['Orig Market'] = analysis_df['Orig Market'].astype(str).str.strip().str.upper()\n",
    "    analysis_df['Dup Market'] = analysis_df['Dup Market'].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # 4. RUN VALIDATION\n",
    "    # The function modifies df_bsr in place.\n",
    "    validation_result = validate_dup_channel_existence(df_bsr, analysis_df)\n",
    "    \n",
    "    print(\"\\n✅ CHECK RESULT:\")\n",
    "    print(validation_result)\n",
    "    \n",
    "    if validation_result.get('rows_flagged', 0) > 0:\n",
    "        print(\"\\n--- Sample of Flagged BSR Rows ---\")\n",
    "        print(df_bsr[df_bsr[validation_result['details'].get('flag_column', 'QC_Dup_Channel_Existence_Flag')] != 'OK'][[\n",
    "            'Market', 'TV-Channel', 'Broadcaster', validation_result['details'].get('flag_column', 'QC_Dup_Channel_Existence_Flag')\n",
    "        ]].head(10).to_markdown())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File Error: Ensure both BSR ({BSR_FILE_PATH}) and Macro ({MACRO_FILE_PATH}) files exist. Error: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Column Error: Missing expected column in BSR or Macro file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59fff9c-0bcc-42d5-b505-eee3448cc40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90c366a8-c8a5-4737-a1a0-94b4f179597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Local File Processing ---\n",
      "\n",
      "✅ VALIDATION COMPLETE:\n",
      "Checked 136 unique Dup Market/Channel requirements. Flagged 509 rows in markets missing required channels.\n",
      "--------------------------------------------------\n",
      "✅ Success! Processed file saved locally to: data\\QC_Processed_BSR_Channel_Existence.xlsx\n",
      "Total rows flagged: 509\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, Any, List, Set\n",
    "\n",
    "# --- FILE PATHS AND CONSTANTS ---\n",
    "# NOTE: These paths must be correct relative to where you run this script.\n",
    "BSR_FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "BSR_SHEET_NAME = \"Worksheet\"\n",
    "BSR_HEADER_ROW = 5 \n",
    "\n",
    "MACRO_FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "MACRO_SHEET_NAME = \"Data Core\"\n",
    "MACRO_FILE_PATH = os.path.join(\"data\", MACRO_FILE_NAME) \n",
    "MACRO_HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "REQUIRED_RULE_COLS = ['Orig Market', 'Dup Market', 'Dup Channel'] \n",
    "\n",
    "OUTPUT_FILE_NAME = \"QC_Processed_BSR_Channel_Existence.xlsx\"\n",
    "\n",
    "# --- HELPER FUNCTION FOR CHANNEL NAME NORMALIZATION (Must be accessible) ---\n",
    "def normalize_channel_name(channel_series):\n",
    "    \"\"\"Removes country codes and parentheses to get core channel identity.\"\"\"\n",
    "    normalized = channel_series.astype(str).str.strip().str.upper()\n",
    "    normalized = normalized.str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+ARG|\\s+BOL|\\s+CHL|\\s+PER|\\s+SWE|\\s+DE', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+TV', '', regex=True)\n",
    "    return normalized.str.strip()\n",
    "\n",
    "# =========================================================================\n",
    "# === 1. VALIDATION FUNCTION (Simulated BSRValidator Method) ==============\n",
    "# =========================================================================\n",
    "\n",
    "def validate_dup_channel_existence(df: pd.DataFrame, df_dup_rules: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Checks if every 'Dup Channel' required by the Duplication Rules is actually present \n",
    "    in the list of 'TV-Channel's within the corresponding 'Dup Market' of the BSR.\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    FLAG_COLUMN = 'QC_Dup_Channel_Existence_Flag'\n",
    "    \n",
    "    # 1. Initialization and Checks\n",
    "    df[FLAG_COLUMN] = 'OK'\n",
    "    REQUIRED_BSR_COLS = ['Market', 'TV-Channel']\n",
    "    \n",
    "    # Pre-check is crucial here since the main script handles the loading\n",
    "    if not all(col in df.columns for col in REQUIRED_BSR_COLS):\n",
    "        print(f\"FATAL: BSR is missing columns: {list(set(REQUIRED_BSR_COLS) - set(df.columns))}\")\n",
    "        return {\"check_key\": \"dup_channel_existence\", \"status\": \"Skipped\", \"action\": \"Duplication Channel Check\", \"details\": {\"rows_flagged\": 0}}\n",
    "    \n",
    "    # 2. Data Preparation for Efficient Lookup\n",
    "    \n",
    "    # Standardize the BSR Market and Channel names (UPPER/Strip)\n",
    "    bsr_df_check = df.copy()\n",
    "    bsr_df_check['Market_Norm'] = bsr_df_check['Market'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Apply normalization to BSR channels only for the lookup map values\n",
    "    bsr_df_check['TV-Channel_Norm'] = normalize_channel_name(bsr_df_check['TV-Channel'])\n",
    "    \n",
    "    # Create a dictionary for quick lookup of existing channels in the BSR:\n",
    "    # Key: Market Name (Normalized) -> Value: Set of existing TV-Channels (Normalized)\n",
    "    existing_channels_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].apply(set).to_dict()\n",
    "    \n",
    "    # 3. Iterate Through Duplication Rules and Validate\n",
    "    \n",
    "    missing_channels_log = []\n",
    "    \n",
    "    # Filter and prepare rules data\n",
    "    rules_to_check = df_dup_rules[REQUIRED_RULE_COLS].drop_duplicates().copy()\n",
    "    rules_to_check['Dup Market_Norm'] = rules_to_check['Dup Market'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Apply normalization to the REQUIRED channel name from the rule sheet\n",
    "    rules_to_check['Required_Channel_Norm'] = normalize_channel_name(rules_to_check['Dup Channel'])\n",
    "    \n",
    "    rows_flagged = 0\n",
    "    \n",
    "    for index, rule in rules_to_check.iterrows():\n",
    "        dup_market = rule['Dup Market_Norm']\n",
    "        required_channel_norm = rule['Required_Channel_Norm']\n",
    "        orig_market = rule['Orig Market']\n",
    "        \n",
    "        # Look up the set of existing channels in the target Dup Market\n",
    "        existing_channels = existing_channels_map.get(dup_market, set())\n",
    "        \n",
    "        # 4. Validation Check: Does the required normalized channel exist in the target market's set?\n",
    "        if required_channel_norm not in existing_channels:\n",
    "            \n",
    "            # Log the specific failure reason\n",
    "            missing_channels_log.append({\n",
    "                \"Orig_Market\": orig_market,\n",
    "                \"Dup_Market\": rule['Dup Market'], \n",
    "                \"Missing_Channel\": rule['Dup Channel'], # Use raw channel name for report clarity\n",
    "                \"Normalized_Match_Key\": required_channel_norm\n",
    "            })\n",
    "            \n",
    "            # 5. Apply Flag to the BSR (Flag all rows in the target Dup Market)\n",
    "            flag_mask = (df['Market'].astype(str).str.strip().str.upper() == dup_market)\n",
    "            \n",
    "            flag_message = f\"Completeness Error: Missing required Dup Channel '{rule['Dup Channel']}' (Source: {orig_market}).\"\n",
    "            \n",
    "            current_flags = df.loc[flag_mask, FLAG_COLUMN]\n",
    "            rows_to_flag = flag_mask & (current_flags == 'OK')\n",
    "            \n",
    "            df.loc[rows_to_flag, FLAG_COLUMN] = flag_message\n",
    "            rows_flagged += rows_to_flag.sum()\n",
    "\n",
    "\n",
    "    final_status = \"Completed\" if rows_flagged == 0 else \"Flagged\"\n",
    "\n",
    "    return {\n",
    "        \"check_key\": \"dup_channel_existence\",\n",
    "        \"status\": final_status,\n",
    "        \"action\": \"Duplication Channel Check\",\n",
    "        \"description\": f\"Checked {len(rules_to_check)} unique Dup Market/Channel requirements. Flagged {rows_flagged} rows in markets missing required channels.\",\n",
    "        \"details\": {\n",
    "            \"rows_flagged\": int(rows_flagged),\n",
    "            \"missing_requirements_count\": len(missing_channels_log),\n",
    "            \"missing_channels_list\": missing_channels_log\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# =========================================================================\n",
    "# === 2. EXECUTION AND SAVE (LOCAL FILESYSTEM) ============================\n",
    "# =========================================================================\n",
    "\n",
    "try:\n",
    "    print(\"--- Starting Local File Processing ---\")\n",
    "    \n",
    "    # 1. LOAD BSR DATA (Main Data)\n",
    "    df_bsr = pd.read_excel(BSR_FILE_PATH, sheet_name=BSR_SHEET_NAME, header=BSR_HEADER_ROW)\n",
    "    df_bsr.columns = [str(c).strip() for c in df_bsr.columns]\n",
    "\n",
    "    # 2. LOAD AND FILTER MACRO DATA (Duplication Rules)\n",
    "    df_macro = pd.read_excel(MACRO_FILE_PATH, sheet_name=MACRO_SHEET_NAME, header=MACRO_HEADER_INDEX)\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    # Final Duplication Rules DataFrame\n",
    "    df_dup_rules = filtered_df[REQUIRED_RULE_COLS].copy()\n",
    "    \n",
    "    # 3. RUN VALIDATION (Function modifies df_bsr in place)\n",
    "    validation_result = validate_dup_channel_existence(df_bsr, df_dup_rules)\n",
    "    \n",
    "    print(\"\\n✅ VALIDATION COMPLETE:\")\n",
    "    print(validation_result.get('description'))\n",
    "    \n",
    "    # 4. SAVE PROCESSED FILE\n",
    "    output_path = os.path.join(os.path.dirname(BSR_FILE_PATH), OUTPUT_FILE_NAME)\n",
    "    df_bsr.to_excel(output_path, index=False, sheet_name=BSR_SHEET_NAME)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"✅ Success! Processed file saved locally to: {output_path}\")\n",
    "    print(f\"Total rows flagged: {validation_result.get('details', {}).get('rows_flagged', 0)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File Error: Ensure BSR ({BSR_FILE_PATH}) and Macro ({MACRO_FILE_PATH}) files exist. Error: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Column Error: Missing expected column in BSR or Macro file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01f508-e119-4ef7-ae40-3d3a4140cb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1f3bd-d94c-4d92-9f4f-8d19e5c87898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf35d02b-da31-4bb6-a619-637957b3fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Local File Processing ---\n",
      "\n",
      "✅ VALIDATION COMPLETE:\n",
      "Total Rows Flagged: 509\n",
      "Total Unique Market Pairs Missing Channels: 100\n",
      "--------------------------------------------------\n",
      "✅ Success! Processed file saved locally to: data\\QC_Processed_BSR_Channel_Existence.xlsx\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, Any, List, Set\n",
    "\n",
    "# --- FILE PATHS AND CONSTANTS ---\n",
    "# NOTE: These paths must be correct relative to where you run this script.\n",
    "BSR_FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "BSR_SHEET_NAME = \"Worksheet\"\n",
    "BSR_HEADER_ROW = 5 \n",
    "\n",
    "MACRO_FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "MACRO_SHEET_NAME = \"Data Core\"\n",
    "MACRO_FILE_PATH = os.path.join(\"data\", MACRO_FILE_NAME) \n",
    "MACRO_HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "REQUIRED_RULE_COLS = ['Orig Market', 'Dup Market', 'Dup Channel'] \n",
    "\n",
    "OUTPUT_FILE_NAME = \"QC_Processed_BSR_Channel_Existence.xlsx\"\n",
    "\n",
    "# --- HELPER FUNCTION FOR CHANNEL NAME NORMALIZATION ---\n",
    "def normalize_channel_name(channel_series):\n",
    "    \"\"\"Removes country codes and parentheses to get core channel identity.\"\"\"\n",
    "    normalized = channel_series.astype(str).str.strip().str.upper()\n",
    "    normalized = normalized.str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+ARG|\\s+BOL|\\s+CHL|\\s+PER|\\s+SWE|\\s+DE', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+TV', '', regex=True)\n",
    "    return normalized.str.strip()\n",
    "\n",
    "# =========================================================================\n",
    "# === 1. VALIDATION FUNCTION (STANDALONE VERSION) =========================\n",
    "# =========================================================================\n",
    "\n",
    "def validate_dup_channel_existence(df: pd.DataFrame, df_dup_rules: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Checks if every 'Dup Channel' required by the Duplication Rules is actually present \n",
    "    in the list of 'TV-Channel's within the corresponding 'Dup Market' of the BSR.\n",
    "    Reports the full list of missing channels for each market pair.\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    FLAG_COLUMN = 'QC_Dup_Channel_Existence_Flag'\n",
    "    \n",
    "    # 1. Initialization and Checks\n",
    "    df[FLAG_COLUMN] = 'OK'\n",
    "    REQUIRED_BSR_COLS = ['Market', 'TV-Channel']\n",
    "\n",
    "    if not all(col in df.columns for col in REQUIRED_BSR_COLS) or \\\n",
    "       not all(col in df_dup_rules.columns for col in REQUIRED_RULE_COLS):\n",
    "        return {\n",
    "            \"check_key\": \"dup_channel_existence\", \"status\": \"Skipped\",\n",
    "            \"action\": \"Duplication Channel Check\",\n",
    "            \"description\": \"Skipped: Missing required columns in BSR or Rule set.\",\n",
    "            \"details\": {\"rows_flagged\": 0}\n",
    "        }\n",
    "    \n",
    "    # 2. Data Preparation for Efficient Lookup\n",
    "    \n",
    "    bsr_df_check = df[['Market', 'TV-Channel']].copy()\n",
    "    bsr_df_check['Market_Norm'] = bsr_df_check['Market'].astype(str).str.strip().str.upper()\n",
    "    bsr_df_check['TV-Channel_Norm'] = normalize_channel_name(bsr_df_check['TV-Channel'])\n",
    "    \n",
    "    existing_channels_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].apply(set).to_dict()\n",
    "    \n",
    "    # 3. Iterate Through Duplication Rules and Validate\n",
    "    \n",
    "    missing_channels_log = []\n",
    "    \n",
    "    # Use the variable name 'rules_to_check_df' to avoid confusion if needed elsewhere\n",
    "    rules_to_check_df = df_dup_rules[REQUIRED_RULE_COLS].drop_duplicates().copy()\n",
    "    rules_to_check_df['Dup Market_Norm'] = rules_to_check_df['Dup Market'].astype(str).str.strip().str.upper()\n",
    "    rules_to_check_df['Required_Channel_Norm'] = normalize_channel_name(rules_to_check_df['Dup Channel'])\n",
    "    \n",
    "    rows_flagged = 0\n",
    "    \n",
    "    for index, rule in rules_to_check_df.iterrows():\n",
    "        dup_market = rule['Dup Market_Norm']\n",
    "        required_channel_norm = rule['Required_Channel_Norm']\n",
    "        orig_market = rule['Orig Market']\n",
    "        \n",
    "        existing_channels = existing_channels_map.get(dup_market, set())\n",
    "        \n",
    "        # 4. Validation Check: Does the required normalized channel exist in the target market's set?\n",
    "        if required_channel_norm not in existing_channels:\n",
    "            \n",
    "            # --- Collect All Missing Channels for this Market Pair (The User's Request) ---\n",
    "            # Re-filter the original rules DF to get ALL required channels for this pair\n",
    "            all_required_for_pair = df_dup_rules[\n",
    "                (df_dup_rules['Orig Market'] == orig_market) & \n",
    "                (df_dup_rules['Dup Market'] == rule['Dup Market'])\n",
    "            ]['Dup Channel'].unique()\n",
    "            \n",
    "            # Now, check the missing status for this ENTIRE group\n",
    "            current_missing_channels = [\n",
    "                ch for ch in all_required_for_pair \n",
    "                if normalize_channel_name(pd.Series([ch])).iloc[0] not in existing_channels\n",
    "            ]\n",
    "            \n",
    "            # Log the specific failure reason\n",
    "            missing_channels_log.append({\n",
    "                \"Orig_Market\": orig_market,\n",
    "                \"Dup_Market\": rule['Dup Market'], \n",
    "                \"Missing_Channels_Count\": len(current_missing_channels),\n",
    "                \"Missing_Channels_List\": sorted(current_missing_channels)\n",
    "            })\n",
    "            \n",
    "            # 5. Apply Flag to the BSR\n",
    "            flag_mask = (df['Market'].astype(str).str.strip().str.upper() == dup_market)\n",
    "            \n",
    "            flag_message = f\"Completeness Error: {len(current_missing_channels)} Dup Channel(s) missing (Source: {orig_market}).\"\n",
    "            \n",
    "            current_flags = df.loc[flag_mask, FLAG_COLUMN]\n",
    "            rows_to_flag = flag_mask & (current_flags == 'OK')\n",
    "            \n",
    "            df.loc[rows_to_flag, FLAG_COLUMN] = flag_message\n",
    "            rows_flagged += rows_to_flag.sum()\n",
    "\n",
    "\n",
    "    final_status = \"Completed\" if rows_flagged == 0 else \"Flagged\"\n",
    "\n",
    "    return {\n",
    "        \"check_key\": \"dup_channel_existence\",\n",
    "        \"status\": final_status,\n",
    "        \"action\": \"Duplication Channel Check\",\n",
    "        \"description\": f\"Checked Duplication rules. Flagged {rows_flagged} rows in markets missing required channels.\",\n",
    "        \"details\": {\n",
    "            \"rows_flagged\": int(rows_flagged),\n",
    "            \"missing_market_pairs_count\": len(missing_channels_log),\n",
    "            \"missing_market_details\": missing_channels_log\n",
    "        }\n",
    "    }\n",
    "\n",
    "# =========================================================================\n",
    "# === 2. EXECUTION AND SAVE (LOCAL FILESYSTEM) ============================\n",
    "# =========================================================================\n",
    "\n",
    "try:\n",
    "    print(\"--- Starting Local File Processing ---\")\n",
    "    \n",
    "    # 1. LOAD BSR DATA (Main Data)\n",
    "    df_bsr = pd.read_excel(BSR_FILE_PATH, sheet_name=BSR_SHEET_NAME, header=BSR_HEADER_ROW)\n",
    "    df_bsr.columns = [str(c).strip() for c in df_bsr.columns]\n",
    "\n",
    "    # 2. LOAD AND FILTER MACRO DATA (Duplication Rules)\n",
    "    df_macro = pd.read_excel(MACRO_FILE_PATH, sheet_name=MACRO_SHEET_NAME, header=MACRO_HEADER_INDEX)\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    # Final Duplication Rules DataFrame\n",
    "    df_dup_rules = filtered_df[REQUIRED_RULE_COLS].copy()\n",
    "    \n",
    "    # 3. RUN VALIDATION (Function modifies df_bsr in place)\n",
    "    # The fix ensures this function runs without throwing the NameError\n",
    "    validation_result = validate_dup_channel_existence(df_bsr, df_dup_rules)\n",
    "    \n",
    "    print(\"\\n✅ VALIDATION COMPLETE:\")\n",
    "    print(f\"Total Rows Flagged: {validation_result['details'].get('rows_flagged', 0)}\")\n",
    "    print(f\"Total Unique Market Pairs Missing Channels: {validation_result['details'].get('missing_market_pairs_count', 0)}\")\n",
    "    \n",
    "    # 4. SAVE PROCESSED FILE\n",
    "    output_path = os.path.join(os.path.dirname(BSR_FILE_PATH), OUTPUT_FILE_NAME)\n",
    "    df_bsr.to_excel(output_path, index=False, sheet_name=BSR_SHEET_NAME)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"✅ Success! Processed file saved locally to: {output_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File Error: Ensure both BSR ({BSR_FILE_PATH}) and Macro ({MACRO_FILE_PATH}) files exist. Error: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Column Error: Missing expected column in BSR or Macro file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred during execution: {e}. Check if required columns are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8f1aa0a-bad2-45b4-8a6e-0c9abdcdc528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Local File Processing ---\n",
      "\n",
      "✅ VALIDATION COMPLETE:\n",
      "Total Rows Flagged: 509\n",
      "Total Unique Market Pairs Missing Channels: 28\n",
      "--------------------------------------------------\n",
      "✅ Success! Processed file saved locally to: data\\QC_Processed_BSR_Channel_Existence.xlsx\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, Any, List, Set\n",
    "\n",
    "# --- FILE PATHS AND CONSTANTS ---\n",
    "BSR_FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "BSR_SHEET_NAME = \"Worksheet\"\n",
    "BSR_HEADER_ROW = 5 \n",
    "\n",
    "MACRO_FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "MACRO_SHEET_NAME = \"Data Core\"\n",
    "MACRO_FILE_PATH = os.path.join(\"data\", MACRO_FILE_NAME) \n",
    "MACRO_HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "REQUIRED_RULE_COLS = ['Orig Market', 'Dup Market', 'Dup Channel'] \n",
    "\n",
    "# Output file path definition\n",
    "OUTPUT_DIR = os.path.dirname(BSR_FILE_PATH)\n",
    "OUTPUT_FILE_NAME = \"QC_Processed_BSR_Channel_Existence.xlsx\"\n",
    "OUTPUT_FULL_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILE_NAME)\n",
    "\n",
    "# --- HELPER FUNCTION FOR CHANNEL NAME NORMALIZATION ---\n",
    "def normalize_channel_name(channel_series):\n",
    "    \"\"\"Removes country codes and parentheses to get core channel identity.\"\"\"\n",
    "    normalized = channel_series.astype(str).str.strip().str.upper()\n",
    "    normalized = normalized.str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+ARG|\\s+BOL|\\s+CHL|\\s+PER|\\s+SWE|\\s+DE', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+TV', '', regex=True)\n",
    "    return normalized.str.strip()\n",
    "\n",
    "# =========================================================================\n",
    "# === 1. VALIDATION FUNCTION (Simulated BSRValidator Method) ==============\n",
    "# =========================================================================\n",
    "\n",
    "def validate_dup_channel_existence(df: pd.DataFrame, df_dup_rules: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Checks if every 'Dup Channel' required by the Duplication Rules is actually present \n",
    "    in the list of 'TV-Channel's within the corresponding 'Dup Market' of the BSR.\n",
    "    Reports the full context of existing and missing channels.\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    FLAG_COLUMN = 'QC_Dup_Channel_Existence_Flag'\n",
    "    \n",
    "    # 1. Initialization and Checks\n",
    "    df[FLAG_COLUMN] = 'OK'\n",
    "    REQUIRED_BSR_COLS = ['Market', 'TV-Channel']\n",
    "\n",
    "    if not all(col in df.columns for col in REQUIRED_BSR_COLS) or \\\n",
    "       not all(col in df_dup_rules.columns for col in REQUIRED_RULE_COLS):\n",
    "        return {\n",
    "            \"check_key\": \"dup_channel_existence\", \"status\": \"Skipped\",\n",
    "            \"action\": \"Duplication Channel Check\",\n",
    "            \"description\": \"Skipped: Missing required columns in BSR or Rule set.\",\n",
    "            \"details\": {\"rows_flagged\": 0}\n",
    "        }\n",
    "    \n",
    "    # 2. Data Preparation for Efficient Lookup\n",
    "    \n",
    "    bsr_df_check = df[['Market', 'TV-Channel']].copy()\n",
    "    bsr_df_check['Market_Norm'] = bsr_df_check['Market'].astype(str).str.strip().str.upper()\n",
    "    bsr_df_check['TV-Channel_Norm'] = normalize_channel_name(bsr_df_check['TV-Channel'])\n",
    "    \n",
    "    existing_channels_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].apply(set).to_dict()\n",
    "    orig_channel_count_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].nunique().to_dict()\n",
    "\n",
    "    # 3. Aggregate Rules and Prepare for Validation\n",
    "    missing_channels_log = []\n",
    "    rules_grouped = df_dup_rules.groupby(['Orig Market', 'Dup Market'])\n",
    "    df_dup_rules['Required_Channel_Norm'] = normalize_channel_name(df_dup_rules['Dup Channel'])\n",
    "    \n",
    "    rows_flagged = 0\n",
    "    \n",
    "    # Iterate over each unique (Source Market, Target Market) pair\n",
    "    for (orig_market_raw, dup_market_raw), group in rules_grouped:\n",
    "        \n",
    "        orig_market = orig_market_raw.upper().strip()\n",
    "        dup_market = dup_market_raw.upper().strip()\n",
    "        \n",
    "        required_channels_set = set(group['Required_Channel_Norm'].unique())\n",
    "        existing_channels = existing_channels_map.get(dup_market, set())\n",
    "        \n",
    "        missing_channels = required_channels_set.difference(existing_channels)\n",
    "        \n",
    "        # 4. Validation Check and Logging\n",
    "        if missing_channels:\n",
    "            \n",
    "            # Log the specific failure reason\n",
    "            missing_channels_log.append({\n",
    "                \"Orig_Market\": orig_market_raw,\n",
    "                \"Dup_Market\": dup_market_raw, \n",
    "                \"Orig_Channel_Count\": orig_channel_count_map.get(orig_market, 0),\n",
    "                \"Dup_Channel_Exist_Count\": len(existing_channels),\n",
    "                \"Missing_Channels_Count\": len(missing_channels),\n",
    "                \"Missing_Channels_List\": sorted(list(missing_channels))\n",
    "            })\n",
    "            \n",
    "            # 5. Apply Flag to the BSR\n",
    "            flag_mask = (df['Market'].astype(str).str.strip().str.upper() == dup_market)\n",
    "            flag_message = f\"Completeness Error: {len(missing_channels)} Dup Channel(s) missing (Source: {orig_market_raw}).\"\n",
    "            current_flags = df.loc[flag_mask, FLAG_COLUMN]\n",
    "            rows_to_flag = flag_mask & (current_flags == 'OK')\n",
    "            \n",
    "            df.loc[rows_to_flag, FLAG_COLUMN] = flag_message\n",
    "            rows_flagged += rows_to_flag.sum()\n",
    "\n",
    "\n",
    "    final_status = \"Completed\" if rows_flagged == 0 else \"Flagged\"\n",
    "\n",
    "    return {\n",
    "        \"check_key\": \"dup_channel_existence\",\n",
    "        \"status\": final_status,\n",
    "        \"action\": \"Duplication Channel Check (List of Missing)\",\n",
    "        \"description\": f\"Checked Duplication rules. Flagged {rows_flagged} rows in markets missing required channels.\",\n",
    "        \"details\": {\n",
    "            \"rows_flagged\": int(rows_flagged),\n",
    "            \"missing_market_pairs_count\": len(missing_channels_log),\n",
    "            \"missing_market_details\": missing_channels_log\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# =========================================================================\n",
    "# === 2. EXECUTION AND SAVE (LOCAL FILESYSTEM) ============================\n",
    "# =========================================================================\n",
    "\n",
    "try:\n",
    "    print(\"--- Starting Local File Processing ---\")\n",
    "    \n",
    "    # 1. LOAD BSR DATA (Main Data)\n",
    "    df_bsr = pd.read_excel(BSR_FILE_PATH, sheet_name=BSR_SHEET_NAME, header=BSR_HEADER_ROW)\n",
    "    df_bsr.columns = [str(c).strip() for c in df_bsr.columns]\n",
    "\n",
    "    # 2. LOAD AND FILTER MACRO DATA (Duplication Rules)\n",
    "    df_macro = pd.read_excel(MACRO_FILE_PATH, sheet_name=MACRO_SHEET_NAME, header=MACRO_HEADER_INDEX)\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    # Final Duplication Rules DataFrame\n",
    "    df_dup_rules = filtered_df[['Orig Market', 'Dup Market', 'Dup Channel']].copy()\n",
    "    \n",
    "    # 3. RUN VALIDATION (Function modifies df_bsr in place)\n",
    "    validation_result = validate_dup_channel_existence(df_bsr, df_dup_rules)\n",
    "    \n",
    "    print(\"\\n✅ VALIDATION COMPLETE:\")\n",
    "    print(f\"Total Rows Flagged: {validation_result['details'].get('rows_flagged', 0)}\")\n",
    "    print(f\"Total Unique Market Pairs Missing Channels: {validation_result['details'].get('missing_market_pairs_count', 0)}\")\n",
    "    \n",
    "    # 4. SAVE PROCESSED FILE\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    df_bsr.to_excel(OUTPUT_FULL_PATH, index=False, sheet_name=BSR_SHEET_NAME)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"✅ Success! Processed file saved locally to: {OUTPUT_FULL_PATH}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File Error: Ensure both BSR ({BSR_FILE_PATH}) and Macro ({MACRO_FILE_PATH}) files exist. Error: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Column Error: Missing expected column in BSR or Macro file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09272e9e-f69d-4824-8915-1b30939416f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf78a9-9801-4b4c-aa76-6a9a4fc7e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6d50c24-4b56-46bd-bf72-4c092c0f8706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Local File Processing ---\n",
      "\n",
      "✅ VALIDATION COMPLETE:\n",
      "Total Rows Flagged: 509\n",
      "Total Unique Market Pairs Missing Channels: 28\n",
      "--------------------------------------------------\n",
      "✅ Success! Processed file saved locally to: data\\QC_Processed_BSR_Channel_Existence.xlsx\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, Any, List, Set\n",
    "\n",
    "# --- FILE PATHS AND CONSTANTS ---\n",
    "# NOTE: These paths must be correct relative to where you run this script.\n",
    "BSR_FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "BSR_SHEET_NAME = \"Worksheet\"\n",
    "BSR_HEADER_ROW = 5 \n",
    "\n",
    "MACRO_FILE_NAME = \"Macro - BSA Market Duplicator 3.5-F1.xlsm\"\n",
    "MACRO_SHEET_NAME = \"Data Core\"\n",
    "MACRO_FILE_PATH = os.path.join(\"data\", MACRO_FILE_NAME) \n",
    "MACRO_HEADER_INDEX = 1 \n",
    "SEARCH_TERM = \"Formula 1\"\n",
    "REQUIRED_RULE_COLS = ['Orig Market', 'Dup Market', 'Dup Channel'] \n",
    "\n",
    "OUTPUT_DIR = os.path.dirname(BSR_FILE_PATH)\n",
    "OUTPUT_FILE_NAME = \"QC_Processed_BSR_Channel_Existence.xlsx\"\n",
    "OUTPUT_FULL_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILE_NAME)\n",
    "\n",
    "\n",
    "# --- HELPER FUNCTION FOR CHANNEL NAME NORMALIZATION ---\n",
    "def normalize_channel_name(channel_series):\n",
    "    \"\"\"Removes country codes and parentheses to get core channel identity.\"\"\"\n",
    "    normalized = channel_series.astype(str).str.strip().str.upper()\n",
    "    normalized = normalized.str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+ARG|\\s+BOL|\\s+CHL|\\s+PER|\\s+SWE|\\s+DE|\\s+AFR|\\s+PCA|\\s+COL|\\s+ECU|\\s+URY|\\s+MEX|\\s+JPN|\\s+LTU|\\s+CHE|\\s+FRA', '', regex=True)\n",
    "    normalized = normalized.str.replace(r'\\s+TV', '', regex=True)\n",
    "    return normalized.str.strip()\n",
    "\n",
    "# =========================================================================\n",
    "# === 1. VALIDATION FUNCTION (Simulated BSRValidator Method) ==============\n",
    "# =========================================================================\n",
    "\n",
    "def validate_dup_channel_existence(df: pd.DataFrame, df_dup_rules: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Checks if every 'Dup Channel' required by the Duplication Rules is actually present \n",
    "    in the list of 'TV-Channel's within the corresponding 'Dup Market' of the BSR.\n",
    "    Reports the full list of missing channels for each market pair.\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    FLAG_COLUMN = 'QC_Dup_Channel_Existence_Flag'\n",
    "    \n",
    "    # 1. Initialization and Checks\n",
    "    df[FLAG_COLUMN] = 'OK'\n",
    "    REQUIRED_BSR_COLS = ['Market', 'TV-Channel']\n",
    "\n",
    "    if not all(col in df.columns for col in REQUIRED_BSR_COLS) or \\\n",
    "       not all(col in df_dup_rules.columns for col in REQUIRED_RULE_COLS):\n",
    "        return {\n",
    "            \"check_key\": \"dup_channel_existence\", \"status\": \"Skipped\",\n",
    "            \"action\": \"Duplication Channel Check\",\n",
    "            \"description\": \"Skipped: Missing required columns in BSR or Rule set.\",\n",
    "            \"details\": {\"rows_flagged\": 0}\n",
    "        }\n",
    "    \n",
    "    # 2. Data Preparation for Efficient Lookup\n",
    "    \n",
    "    bsr_df_check = df[['Market', 'TV-Channel']].copy()\n",
    "    bsr_df_check['Market_Norm'] = bsr_df_check['Market'].astype(str).str.strip().str.upper()\n",
    "    \n",
    "    # Apply normalization to BSR channels for the lookup map values\n",
    "    bsr_df_check['TV-Channel_Norm'] = normalize_channel_name(bsr_df_check['TV-Channel'])\n",
    "    \n",
    "    # Create a dictionary for quick lookup of existing channels in the BSR:\n",
    "    existing_channels_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].apply(set).to_dict()\n",
    "    orig_channel_count_map = bsr_df_check.groupby('Market_Norm')['TV-Channel_Norm'].nunique().to_dict()\n",
    "\n",
    "    # 3. Aggregate Rules and Prepare for Validation\n",
    "    \n",
    "    missing_channels_log = []\n",
    "    \n",
    "    # Use the variable name 'rules_to_check_df' to avoid confusion if needed elsewhere\n",
    "    rules_to_check_df = df_dup_rules[REQUIRED_RULE_COLS].copy()\n",
    "    rules_grouped = rules_to_check_df.groupby(['Orig Market', 'Dup Market'])\n",
    "    rules_to_check_df['Required_Channel_Norm'] = normalize_channel_name(rules_to_check_df['Dup Channel'])\n",
    "    \n",
    "    rows_flagged = 0\n",
    "    \n",
    "    # Iterate over each unique (Source Market, Target Market) pair\n",
    "    for (orig_market_raw, dup_market_raw), group in rules_grouped:\n",
    "        \n",
    "        orig_market = orig_market_raw.upper().strip()\n",
    "        dup_market = dup_market_raw.upper().strip()\n",
    "        \n",
    "        # Get the set of ALL channels required for this specific duplication pair\n",
    "        required_channels_set = set(group['Required_Channel_Norm'].unique())\n",
    "        \n",
    "        # Get the channels currently existing in the BSR for the target market\n",
    "        existing_channels = existing_channels_map.get(dup_market, set())\n",
    "        \n",
    "        # Find the difference: Channels present in REQUIRED set but NOT in EXISTING set\n",
    "        missing_channels = required_channels_set.difference(existing_channels)\n",
    "        \n",
    "        # 4. Validation Check and Logging\n",
    "        if missing_channels:\n",
    "            \n",
    "            # Log the specific failure reason\n",
    "            missing_channels_log.append({\n",
    "                \"Orig_Market\": orig_market_raw,\n",
    "                \"Dup_Market\": dup_market_raw, \n",
    "                \"Orig_Channel_Count\": orig_channel_count_map.get(orig_market, 0),\n",
    "                \"Dup_Channel_Exist_Count\": len(existing_channels),\n",
    "                \"Missing_Channels_Count\": len(missing_channels),\n",
    "                \"Missing_Channels_List\": sorted(list(missing_channels))\n",
    "            })\n",
    "            \n",
    "            # 5. Apply Flag to the BSR\n",
    "            # Format the flag message with the comprehensive list\n",
    "            missing_list_str = \"; \".join(sorted(list(missing_channels)))\n",
    "            flag_message = f\"Completeness Error: {len(missing_channels)} Channel(s) missing. Required: [{missing_list_str}] (Source: {orig_market_raw}).\"\n",
    "            \n",
    "            # Flag ALL rows in the target Dup Market (since the issue is market-wide completeness)\n",
    "            flag_mask = (df['Market'].astype(str).str.strip().str.upper() == dup_market)\n",
    "            \n",
    "            # Only flag rows that were not already flagged\n",
    "            current_flags = df.loc[flag_mask, FLAG_COLUMN]\n",
    "            rows_to_flag = flag_mask & (current_flags == 'OK')\n",
    "            \n",
    "            df.loc[rows_to_flag, FLAG_COLUMN] = flag_message\n",
    "            rows_flagged += rows_to_flag.sum()\n",
    "\n",
    "\n",
    "    final_status = \"Completed\" if rows_flagged == 0 else \"Flagged\"\n",
    "\n",
    "    return {\n",
    "        \"check_key\": \"dup_channel_existence\",\n",
    "        \"status\": final_status,\n",
    "        \"action\": \"Duplication Channel Check\",\n",
    "        \"description\": f\"Checked Duplication rules. Flagged {rows_flagged} rows in markets missing required channels.\",\n",
    "        \"details\": {\n",
    "            \"rows_flagged\": int(rows_flagged),\n",
    "            \"missing_market_pairs_count\": len(missing_channels_log),\n",
    "            \"missing_market_details\": missing_channels_log\n",
    "        }\n",
    "    }\n",
    "\n",
    "# =========================================================================\n",
    "# === 2. EXECUTION AND SAVE (LOCAL FILESYSTEM) ============================\n",
    "# =========================================================================\n",
    "\n",
    "try:\n",
    "    print(\"--- Starting Local File Processing ---\")\n",
    "    \n",
    "    # 1. LOAD BSR DATA (Main Data)\n",
    "    df_bsr = pd.read_excel(BSR_FILE_PATH, sheet_name=BSR_SHEET_NAME, header=BSR_HEADER_ROW)\n",
    "    df_bsr.columns = [str(c).strip() for c in df_bsr.columns]\n",
    "\n",
    "    # 2. LOAD AND FILTER MACRO DATA (Duplication Rules)\n",
    "    df_macro = pd.read_excel(MACRO_FILE_PATH, sheet_name=MACRO_SHEET_NAME, header=MACRO_HEADER_INDEX)\n",
    "    df_macro.columns = [str(c).strip() for c in df_macro.columns]\n",
    "\n",
    "    filtered_df = df_macro[\n",
    "        df_macro['Projects'].astype(str).str.contains(SEARCH_TERM, case=False, na=False)\n",
    "    ].copy()\n",
    "    \n",
    "    # Final Duplication Rules DataFrame\n",
    "    df_dup_rules = filtered_df[['Orig Market', 'Dup Market', 'Dup Channel']].copy()\n",
    "    \n",
    "    # 3. RUN VALIDATION (Function modifies df_bsr in place)\n",
    "    validation_result = validate_dup_channel_existence(df_bsr, df_dup_rules)\n",
    "    \n",
    "    print(\"\\n✅ VALIDATION COMPLETE:\")\n",
    "    print(f\"Total Rows Flagged: {validation_result['details'].get('rows_flagged', 0)}\")\n",
    "    print(f\"Total Unique Market Pairs Missing Channels: {validation_result['details'].get('missing_market_pairs_count', 0)}\")\n",
    "    \n",
    "    # 4. SAVE PROCESSED FILE\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "    df_bsr.to_excel(OUTPUT_FULL_PATH, index=False, sheet_name=BSR_SHEET_NAME)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"✅ Success! Processed file saved locally to: {OUTPUT_FULL_PATH}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File Error: Ensure both BSR ({BSR_FILE_PATH}) and Macro ({MACRO_FILE_PATH}) files exist. Error: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"❌ Column Error: Missing expected column in BSR or Macro file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An unexpected error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1875085-7d88-44d2-9180-68a3b4594fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
