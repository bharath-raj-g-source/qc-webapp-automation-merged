{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab9394c",
   "metadata": {},
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b52a26f-4274-4e9b-9433-2fa2fa34fcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing column 'Start' to string type using .apply(str).\n",
      "Standardizing column 'End' to string type using .apply(str).\n",
      "\n",
      "Total duplicate rows found: 147\n",
      "\n",
      "First 10 duplicate rows (based on TV-Channel, Channel ID, Start, End):\n",
      "                      TV-Channel  Channel ID     Start       End  Region  \\\n",
      "1674  Arenasport 1 (Pan Balkans)      5105.0  13:30:00  14:30:00  Europe   \n",
      "1676  Arenasport 1 (Pan Balkans)      5105.0  13:30:00  14:30:00  Europe   \n",
      "1219           Art Sport 6 (KOS)     39130.0  07:00:00  10:45:00  Europe   \n",
      "1225           Art Sport 6 (KOS)     39130.0  07:00:00  10:45:00  Europe   \n",
      "2973                      Canal+         NaN       nan       nan  Global   \n",
      "2974                      Canal+         NaN       nan       nan  Global   \n",
      "2975                      Canal+         NaN       nan       nan  Global   \n",
      "2976                      Canal+         NaN       nan       nan  Global   \n",
      "2977                      Canal+         NaN       nan       nan  Global   \n",
      "2978                      Canal+         NaN       nan       nan  Global   \n",
      "\n",
      "                   Market  Duration  \\\n",
      "1674  Pan Westren Balkans  01:00:00   \n",
      "1676  Pan Westren Balkans  01:00:00   \n",
      "1219               Kosovo  03:45:00   \n",
      "1225               Kosovo  03:45:00   \n",
      "2973          Switzerland       NaN   \n",
      "2974          Switzerland       NaN   \n",
      "2975          Switzerland       NaN   \n",
      "2976          Switzerland       NaN   \n",
      "2977          Switzerland       NaN   \n",
      "2978          Switzerland       NaN   \n",
      "\n",
      "                                               Combined Broadcaster  \\\n",
      "1674  Velika Britanija: Trening 2 - Moto Sport FORMU...    Arena TV   \n",
      "1676  Velika Britanija: Trening 2 - Moto Sport FORMU...    Arena TV   \n",
      "1219    Formula 1: GP Britania Kualifikimet dhe Gara -    Artmotion   \n",
      "1225    Formula 1: GP Britania Kualifikimet dhe Gara -    Artmotion   \n",
      "2973                                                NaN         NaN   \n",
      "2974                                                NaN         NaN   \n",
      "2975                                                NaN         NaN   \n",
      "2976                                                NaN         NaN   \n",
      "2977                                                NaN         NaN   \n",
      "2978                                                NaN         NaN   \n",
      "\n",
      "     Program Description Program Title  TVR% 3+  Aud Metered (000s) 3+  \\\n",
      "1674                   -             -      NaN                    NaN   \n",
      "1676                   -             -      NaN                    NaN   \n",
      "1219                   -             -      NaN                    NaN   \n",
      "1225                   -             -      NaN                    NaN   \n",
      "2973                 NaN           NaN      NaN                    NaN   \n",
      "2974                 NaN           NaN      NaN                    NaN   \n",
      "2975                 NaN           NaN      NaN                    NaN   \n",
      "2976                 NaN           NaN      NaN                    NaN   \n",
      "2977                 NaN           NaN      NaN                    NaN   \n",
      "2978                 NaN           NaN      NaN                    NaN   \n",
      "\n",
      "     Start (UTC)       Date Program Title  \n",
      "1674    11:30:00 2025-07-04             -  \n",
      "1676    11:30:00 2025-07-06             -  \n",
      "1219    05:00:00 2025-07-07             -  \n",
      "1225    05:00:00 2025-07-08             -  \n",
      "2973         NaN        NaT           NaN  \n",
      "2974         NaN        NaT           NaN  \n",
      "2975         NaN        NaT           NaN  \n",
      "2976         NaN        NaT           NaN  \n",
      "2977         NaN        NaT           NaN  \n",
      "2978         NaN        NaT           NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the DataFrame\n",
    "df = pd.read_excel(\n",
    "    \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "    sheet_name=\"Worksheet\",\n",
    "    header=5\n",
    ")\n",
    "\n",
    "# 2. Define the columns to check and sort by\n",
    "subset_cols = ['TV-Channel', 'Channel ID', 'Start', 'End', 'Region', 'Market', 'Duration' , 'Combined' , 'Broadcaster' , 'Program Description' , 'Program Title' ,'TVR% 3+' ,'Aud Metered (000s) 3+','Start (UTC)'  ]\n",
    "\n",
    "# --- CRITICAL FIX: CONVERT TIME COLUMNS TO STRING (OBJECT) ---\n",
    "# This resolves the 'datetime.datetime' vs 'datetime.time' comparison error.\n",
    "for col in ['Start', 'End']:\n",
    "    # The .apply(str) method is the most robust way to force all mixed contents to string.\n",
    "    print(f\"Standardizing column '{col}' to string type using .apply(str).\")\n",
    "    df[col] = df[col].apply(str)\n",
    "\n",
    "# --- Secondary Fix (Addressing the Deprecation Warning and other 'category' issues) ---\n",
    "# Ensure other non-time columns are not problematic 'category' dtypes\n",
    "for col in subset_cols:\n",
    "    # Using the modern isinstance check to address the DeprecationWarning\n",
    "    if isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "        print(f\"Converting column '{col}' from 'category' to 'object' for sorting.\")\n",
    "        df[col] = df[col].astype('object')\n",
    "\n",
    "# 3. Find all duplicate rows\n",
    "duplicate_mask = df.duplicated(subset=subset_cols, keep=False)\n",
    "duplicate_rows = df[duplicate_mask].copy()\n",
    "\n",
    "# 4. Sort the DataFrame (This should now work reliably)\n",
    "duplicate_rows = duplicate_rows.sort_values(by=subset_cols)\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nTotal duplicate rows found: {duplicate_rows.shape[0]}\")\n",
    "print(\"\\nFirst 10 duplicate rows (based on TV-Channel, Channel ID, Start, End):\")\n",
    "\n",
    "# Columns for output display\n",
    "display_cols = subset_cols + ['Date', 'Program Title']\n",
    "print(duplicate_rows[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e223f0-35ff-4964-8480-bf9d4d6dd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           CROSS-MARKET DUPLICATE CHECK RESULTS                         \n",
      "================================================================================\n",
      "**LOGIC:** Duplicate search was performed on ALL columns EXCEPT 'Market'.\n",
      "**Total duplicate rows found (rows with identical content):** 4\n",
      "**Estimated unique sets of duplicates:** 2\n",
      "================================================================================\n",
      "\n",
      "First 10 duplicate rows (sorted by Market then content to easily spot cross-market pairs):\n",
      "| Market   | TV-Channel   |   Channel ID | Start    | End      | Region   |   Duration | Combined   | Broadcaster   | Program Description   | Program Title   |   TVR% 3+ |   Aud Metered (000s) 3+ | Start (UTC)   | Date       | Program Title   |\n",
      "|:---------|:-------------|-------------:|:---------|:---------|:---------|-----------:|:-----------|:--------------|:----------------------|:----------------|----------:|------------------------:|:--------------|:-----------|:----------------|\n",
      "| Italy    | A            |            1 | 10:00:00 | 11:00:00 | EU       |         60 | C1         | Sky           | PD1                   | Race            |       2.5 |                     150 | 09:00:00      | 2025-01-01 | Race            |\n",
      "| Mexico   | A            |            1 | 10:00:00 | 11:00:00 | EU       |         60 | C1         | Sky           | PD1                   | Race            |       2.5 |                     150 | 09:00:00      | 2025-01-01 | Race            |\n",
      "| USA      | B            |            2 | 11:00:00 | 12:00:00 | NA       |         60 | C2         | ESPN          | PD2                   | Race            |       3   |                     200 | 16:00:00      | 2025-01-01 | Race            |\n",
      "| USA      | B            |            2 | 11:00:00 | 12:00:00 | NA       |         60 | C2         | ESPN          | PD2                   | Race            |       3   |                     200 | 16:00:00      | 2025-01-01 | Race            |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# 1. Dummy DataFrame for demonstration (Replace with your actual file load)\n",
    "data = {\n",
    "    'TV-Channel': ['A', 'A', 'B', 'B'],\n",
    "    'Channel ID': [1, 1, 2, 2],\n",
    "    'Start': ['10:00:00', '10:00:00', '11:00:00', '11:00:00'],\n",
    "    'End': ['11:00:00', '11:00:00', '12:00:00', '12:00:00'],\n",
    "    'Region': ['EU', 'EU', 'NA', 'NA'],\n",
    "    'Market': ['Italy', 'Mexico', 'USA', 'USA'],\n",
    "    'Duration': [60, 60, 60, 60],\n",
    "    'Combined': ['C1', 'C1', 'C2', 'C2'],\n",
    "    'Broadcaster': ['Sky', 'Sky', 'ESPN', 'ESPN'],\n",
    "    'Program Description': ['PD1', 'PD1', 'PD2', 'PD2'],\n",
    "    'Program Title': ['Race', 'Race', 'Race', 'Race'],\n",
    "    'TVR% 3+': [2.5, 2.5, 3.0, 3.0],\n",
    "    'Aud Metered (000s) 3+': [150, 150, 200, 200],\n",
    "    'Start (UTC)': ['09:00:00', '09:00:00', '16:00:00', '16:00:00'],\n",
    "    'Date': ['2025-01-01', '2025-01-01', '2025-01-01', '2025-01-01']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Define the columns to check\n",
    "# *** KEY CHANGE: 'Market' is excluded to find duplicates across markets. ***\n",
    "subset_cols_no_market = [\n",
    "    'TV-Channel', 'Channel ID', 'Start', 'End', 'Region', \n",
    "    'Duration', 'Combined', 'Broadcaster', 'Program Description', \n",
    "    'Program Title', 'TVR% 3+', 'Aud Metered (000s) 3+', 'Start (UTC)'\n",
    "]\n",
    "\n",
    "# --- CRITICAL FIX: CONVERT TIME COLUMNS TO STRING (OBJECT) ---\n",
    "for col in ['Start', 'End']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(str)\n",
    "\n",
    "# --- Secondary Fix: Convert 'category' dtypes to 'object' ---\n",
    "for col in subset_cols_no_market:\n",
    "    if col in df.columns and isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "        df[col] = df[col].astype('object')\n",
    "\n",
    "# 3. Find all duplicate rows \n",
    "duplicate_mask = df.duplicated(subset=subset_cols_no_market, keep=False)\n",
    "duplicate_rows = df[duplicate_mask].copy()\n",
    "\n",
    "# 4. Sort the DataFrame \n",
    "duplicate_rows = duplicate_rows.sort_values(by=['Market'] + subset_cols_no_market)\n",
    "\n",
    "# 5. Display the results with proper summary\n",
    "total_duplicates = duplicate_rows.shape[0]\n",
    "total_unique_duplicate_sets = total_duplicates // 2 if total_duplicates > 0 else 0\n",
    "\n",
    "# Columns for output display\n",
    "display_cols = ['Market'] + subset_cols_no_market + ['Date', 'Program Title']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                           CROSS-MARKET DUPLICATE CHECK RESULTS                         \")\n",
    "print(\"=\"*80)\n",
    "print(f\"**LOGIC:** Duplicate search was performed on ALL columns EXCEPT 'Market'.\")\n",
    "print(f\"**Total duplicate rows found (rows with identical content):** {total_duplicates}\")\n",
    "print(f\"**Estimated unique sets of duplicates:** {total_unique_duplicate_sets}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFirst 10 duplicate rows (sorted by Market then content to easily spot cross-market pairs):\")\n",
    "\n",
    "# Print the table output\n",
    "print(duplicate_rows[display_cols].head(10).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3653d15-35d4-4843-a81f-90880058c9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           CROSS-MARKET DUPLICATE CHECK RESULTS                         \n",
      "================================================================================\n",
      "**FILE CHECKED:** data/WF 3 F1-R12 - Great Britain.xlsx (Sheet: Worksheet)\n",
      "**Total duplicate rows found (rows with identical content):** 640\n",
      "**Total unique duplicate sets (distinct broadcast content):** 0\n",
      "================================================================================\n",
      "\n",
      "--- DETAILED DUPLICATION SUMMARY (MARKET GROUPS) ---\n",
      "This table shows the **Market Groups** formed by content duplication:\n",
      "| Duplicate Count   | Markets Involved   | Program Title   | Broadcaster   | Date   |\n",
      "|-------------------|--------------------|-----------------|---------------|--------|\n",
      "\n",
      "================================================================================\n",
      "INDIVIDUAL DUPLICATED ROWS (Sorted by Market for Manual Review):\n",
      "| Market   | TV-Channel      |   Channel ID | Start    | End      | Region   | Duration   | Combined                                                | Broadcaster   |   Program Description | Program Title                                           |   TVR% 3+ |   Aud Metered (000s) 3+ | Start (UTC)   | Date                | Program Title                                           |\n",
      "|:---------|:----------------|-------------:|:---------|:---------|:---------|:-----------|:--------------------------------------------------------|:--------------|----------------------:|:--------------------------------------------------------|----------:|------------------------:|:--------------|:--------------------|:--------------------------------------------------------|\n",
      "| Andorra  | YouTube         |          nan | nan      | nan      | Global   | nan        | nan                                                     | nan           |                   nan | nan                                                     |       nan |                     nan | nan           | NaT                 | nan                                                     |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 00:00:26 | 01:26:35 | Europe   | 01:26:09   | Formel 1, 1. Freies Training - GP Großbritannien        | Sky           |                   nan | Formel 1, 1. Freies Training - GP Großbritannien        |       nan |                     nan | 22:00:26      | 2025-07-05 00:00:00 | Formel 1, 1. Freies Training - GP Großbritannien        |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 00:00:29 | 00:14:19 | Europe   | 00:13:50   | Formel 1, Qualifying Kompakt - GP Großbritannien        | Sky           |                   nan | Formel 1, Qualifying Kompakt - GP Großbritannien        |       nan |                     nan | 22:00:29      | 2025-07-06 00:00:00 | Formel 1, Qualifying Kompakt - GP Großbritannien        |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 00:30:04 | 01:00:00 | Europe   | 00:29:56   | Formel 1, Rennen Kompakt - GP Großbritannien            | Sky           |                   nan | Formel 1, Rennen Kompakt - GP Großbritannien            |       nan |                     nan | 22:30:04      | 2025-07-08 00:00:00 | Formel 1, Rennen Kompakt - GP Großbritannien            |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 00:30:20 | 01:09:46 | Europe   | 00:39:26   | Formel 1, Hardenacke trifft... (Gast: Sebastian Vettel) | Sky           |                   nan | Formel 1, Hardenacke trifft... (Gast: Sebastian Vettel) |       nan |                     nan | 22:30:20      | 2025-07-04 00:00:00 | Formel 1, Hardenacke trifft... (Gast: Sebastian Vettel) |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 01:15:07 | 01:30:00 | Europe   | 00:14:53   | Formel 1, Warm Up - Das Motorsport Spezial              | Sky           |                   nan | Formel 1, Warm Up - Das Motorsport Spezial              |       nan |                     nan | 23:15:07      | 2025-07-04 00:00:00 | Formel 1, Warm Up - Das Motorsport Spezial              |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 01:30:00 | 02:00:00 | Europe   | 00:30:00   | Formel 1, GP Confidential                               | Sky           |                   nan | Formel 1, GP Confidential                               |       nan |                     nan | 23:30:00      | 2025-07-04 00:00:00 | Formel 1, GP Confidential                               |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 01:30:15 | 02:53:46 | Europe   | 01:23:31   | Formel 1, 2. Freies Training - GP Großbritannien        | Sky           |                   nan | Formel 1, 2. Freies Training - GP Großbritannien        |       nan |                     nan | 23:30:15      | 2025-07-05 00:00:00 | Formel 1, 2. Freies Training - GP Großbritannien        |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 02:15:23 | 03:00:00 | Europe   | 00:44:37   | Formel 1, Qualifying - GP Großbritannien                | Sky           |                   nan | Formel 1, Qualifying - GP Großbritannien                |       nan |                     nan | 00:15:23      | 2025-07-06 00:00:00 | Formel 1, Qualifying - GP Großbritannien                |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 02:45:00 | 03:00:00 | Europe   | 00:15:00   | Formel 1, Top 20: Boxenstopp Chaos                      | Sky           |                   nan | Formel 1, Top 20: Boxenstopp Chaos                      |       nan |                     nan | 00:45:00      | 2025-07-08 00:00:00 | Formel 1, Top 20: Boxenstopp Chaos                      |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 03:00:00 | 03:26:09 | Europe   | 00:26:09   | Formel 1, GP Confidential                               | Sky           |                   nan | Formel 1, GP Confidential                               |       nan |                     nan | 01:00:00      | 2025-07-05 00:00:00 | Formel 1, GP Confidential                               |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 03:00:00 | 03:28:10 | Europe   | 00:28:10   | Formel 1, Rennen Kompakt - GP Großbritannien            | Sky           |                   nan | Formel 1, Rennen Kompakt - GP Großbritannien            |       nan |                     nan | 01:00:00      | 2025-07-07 00:00:00 | Formel 1, Rennen Kompakt - GP Großbritannien            |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 03:00:00 | 03:44:10 | Europe   | 00:44:10   | Formel 1, Qualifying - GP Großbritannien                | Sky           |                   nan | Formel 1, Qualifying - GP Großbritannien                |       nan |                     nan | 01:00:00      | 2025-07-06 00:00:00 | Formel 1, Qualifying - GP Großbritannien                |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 03:30:09 | 03:57:23 | Europe   | 00:27:14   | Formel 1, Rennen Kompakt - GP Österreich                | Sky           |                   nan | Formel 1, Rennen Kompakt - GP Österreich                |       nan |                     nan | 01:30:09      | 2025-07-05 00:00:00 | Formel 1, Rennen Kompakt - GP Österreich                |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 04:00:09 | 06:00:03 | Europe   | 01:59:54   | Formel 1, Rennen - GP Großbritannien                    | Sky           |                   nan | Formel 1, Rennen - GP Großbritannien                    |       nan |                     nan | 02:00:09      | 2025-07-08 00:00:00 | Formel 1, Rennen - GP Großbritannien                    |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 04:00:40 | 05:57:40 | Europe   | 01:57:00   | Formel 1, Rennen - GP Österreich                        | Sky           |                   nan | Formel 1, Rennen - GP Österreich                        |       nan |                     nan | 02:00:40      | 2025-07-03 00:00:00 | Formel 1, Rennen - GP Österreich                        |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 04:30:07 | 04:58:00 | Europe   | 00:27:53   | Formel 1, Rennen Kompakt - GP Großbritannien            | Sky           |                   nan | Formel 1, Rennen Kompakt - GP Großbritannien            |       nan |                     nan | 02:30:07      | 2025-07-07 00:00:00 | Formel 1, Rennen Kompakt - GP Großbritannien            |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 04:45:33 | 04:59:23 | Europe   | 00:13:50   | Formel 1, Qualifying Kompakt - GP Großbritannien        | Sky           |                   nan | Formel 1, Qualifying Kompakt - GP Großbritannien        |       nan |                     nan | 02:45:33      | 2025-07-06 00:00:00 | Formel 1, Qualifying Kompakt - GP Großbritannien        |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 06:00:08 | 06:26:15 | Europe   | 00:26:07   | Formel 1, GP Confidential                               | Sky           |                   nan | Formel 1, GP Confidential                               |       nan |                     nan | 04:00:08      | 2025-07-05 00:00:00 | Formel 1, GP Confidential                               |\n",
      "| Austria  | Sky Sport F1 DE |        35569 | 06:00:12 | 07:26:21 | Europe   | 01:26:09   | Formel 1, 1. Freies Training - GP Großbritannien        | Sky           |                   nan | Formel 1, 1. Freies Training - GP Großbritannien        |       nan |                     nan | 04:00:12      | 2025-07-07 00:00:00 | Formel 1, 1. Freies Training - GP Großbritannien        |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# 1. File Path and Loading (Using your specified file path)\n",
    "FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "SHEET_NAME = \"Worksheet\"\n",
    "HEADER_ROW_INDEX = 5 \n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_ROW_INDEX\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n❌ ERROR: File not found at the specified path: {FILE_PATH}\")\n",
    "    print(\"Please ensure the file exists and the path is correct before running locally.\")\n",
    "    sys.exit(1) \n",
    "\n",
    "# 2. Define the columns to check\n",
    "# The 'Market' column is intentionally EXCLUDED to find duplicates across markets.\n",
    "subset_cols_no_market = [\n",
    "    'TV-Channel', 'Channel ID', 'Start', 'End', 'Region', \n",
    "    'Duration', 'Combined', 'Broadcaster', 'Program Description', \n",
    "    'Program Title', 'TVR% 3+', 'Aud Metered (000s) 3+', 'Start (UTC)'\n",
    "]\n",
    "\n",
    "# --- Data Type Standardization (Critical Fixes) ---\n",
    "for col in ['Start', 'End']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(str)\n",
    "\n",
    "for col in subset_cols_no_market:\n",
    "    if col in df.columns and isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "        df[col] = df[col].astype('object')\n",
    "\n",
    "# 3. Find all duplicate rows\n",
    "duplicate_mask = df.duplicated(subset=subset_cols_no_market, keep=False)\n",
    "duplicate_rows = df[duplicate_mask].copy()\n",
    "\n",
    "# 4. Preparation and Exit if no duplicates are found\n",
    "if duplicate_rows.empty:\n",
    "    print(\"\\n================================================================================\")\n",
    "    print(\"                           CROSS-MARKET DUPLICATE CHECK                         \")\n",
    "    print(\"================================================================================\")\n",
    "    print(\"STATUS: SUCCESS. No cross-market content duplicates were found.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Create a unique identifier for each duplicate set (grouping by content)\n",
    "duplicate_rows['Content_ID'] = duplicate_rows.groupby(subset_cols_no_market).ngroup()\n",
    "\n",
    "# 5. Generate Detailed Summary Statistics (THE MARKET GROUPING)\n",
    "duplicate_summary = duplicate_rows.groupby('Content_ID')['Market'].agg([\n",
    "    ('Duplicate Count', 'size'), \n",
    "    ('Markets Involved', lambda x: ', '.join(sorted(x.unique())))\n",
    "]).reset_index()\n",
    "\n",
    "# Merge key content columns back to the summary for context\n",
    "key_content_cols = ['Program Title', 'Broadcaster', 'Date']\n",
    "content_map = duplicate_rows.drop_duplicates(subset=subset_cols_no_market).set_index('Content_ID')[key_content_cols]\n",
    "duplicate_summary = duplicate_summary.merge(content_map, left_on='Content_ID', right_index=True, how='left')\n",
    "duplicate_summary = duplicate_summary.drop(columns='Content_ID')\n",
    "\n",
    "# Reorder columns and sort by count\n",
    "duplicate_summary = duplicate_summary[['Duplicate Count', 'Markets Involved'] + key_content_cols]\n",
    "duplicate_summary = duplicate_summary.sort_values(by='Duplicate Count', ascending=False)\n",
    "\n",
    "# 6. Display the results\n",
    "total_duplicates = duplicate_rows.shape[0]\n",
    "total_unique_duplicate_sets = duplicate_summary.shape[0]\n",
    "\n",
    "display_cols = ['Market'] + subset_cols_no_market + ['Date', 'Program Title']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                           CROSS-MARKET DUPLICATE CHECK RESULTS                         \")\n",
    "print(\"================================================================================\")\n",
    "print(f\"**FILE CHECKED:** {FILE_PATH} (Sheet: {SHEET_NAME})\")\n",
    "print(f\"**Total duplicate rows found (rows with identical content):** {total_duplicates}\")\n",
    "print(f\"**Total unique duplicate sets (distinct broadcast content):** {total_unique_duplicate_sets}\")\n",
    "print(\"================================================================================\")\n",
    "\n",
    "print(\"\\n--- DETAILED DUPLICATION SUMMARY (MARKET GROUPS) ---\")\n",
    "print(\"This table shows the **Market Groups** formed by content duplication:\")\n",
    "print(duplicate_summary.to_markdown(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INDIVIDUAL DUPLICATED ROWS (Sorted by Market for Manual Review):\")\n",
    "# Sort the duplicate rows for easy manual review\n",
    "duplicate_rows = duplicate_rows.sort_values(by=['Market'] + subset_cols_no_market)\n",
    "print(duplicate_rows[display_cols].head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0423780-4207-44eb-a423-9f779c7176dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                       MARKET COMPARISON: ITALY vs MEXICO                   \n",
      "================================================================================\n",
      "**COMPARISON CRITERIA (MATCHING):** 'TV-Channel, Duration, Broadcaster'.\n",
      "Total rows in Italy: 184\n",
      "Total rows in Mexico: 39\n",
      "================================================================================\n",
      "\n",
      "--- MATCHING CONTENT SUMMARY ---\n",
      "✅ **Total unique content lines matching in BOTH markets:** 0\n",
      "\n",
      "First 10 Matched Content Lines:\n",
      "| Status   | TV-Channel   | Duration   | Broadcaster   |\n",
      "|----------|--------------|------------|---------------|\n",
      "\n",
      "--- UNMATCHED CONTENT SUMMARY ---\n",
      "❌ **Unique content lines found ONLY in Italy:** 184\n",
      "❌ **Unique content lines found ONLY in Mexico:** 39\n",
      "\n",
      "First 5 unique lines found ONLY in Italy:\n",
      "| TV-Channel         | Duration   | Broadcaster   | Program Title                      |\n",
      "|:-------------------|:-----------|:--------------|:-----------------------------------|\n",
      "| SKY SPORT 24 IT    | 00:15:53   | SKY           | F1 Paddock Live Pit Walk 2025 2025 |\n",
      "| SKY SPORT 24 IT    | 00:12:48   | SKY           | Reparto Corse F1 2025 2025         |\n",
      "| SKY SPORT F1 (ITA) | 00:13:34   | SKY           | Reparto Corse F1 2025 2025         |\n",
      "| SKY SPORT F1 (ITA) | 00:42:06   | SKY           | F1 Conf. Stampa Piloti 2025 2025   |\n",
      "| SKY SPORT F1 (ITA) | 00:15:54   | SKY           | F1 Paddock Live Pit Walk 2025 2025 |\n",
      "\n",
      "First 5 unique lines found ONLY in Mexico:\n",
      "| TV-Channel     | Duration   | Broadcaster             | Program Title              |\n",
      "|:---------------|:-----------|:------------------------|:---------------------------|\n",
      "| FOX SPORTS MEX | 02:00:00   | GRUPO MULTIMEDIA LAUMAN | FORMULA 1 -R 2025          |\n",
      "| FOX SPORTS MEX | 01:00:00   | GRUPO MULTIMEDIA LAUMAN | EL SHOW DE LA FORMULA 1 -R |\n",
      "| FOX SPORTS MEX | 00:35:00   | GRUPO MULTIMEDIA LAUMAN | FORMULA 1 -L 2025          |\n",
      "| FOX SPORTS MEX | 00:39:00   | GRUPO MULTIMEDIA LAUMAN | FORMULA UNO INGLATERRA     |\n",
      "| FOX SPORTS MEX | 01:18:00   | GRUPO MULTIMEDIA LAUMAN | FORMULA UNO INGLATERRA     |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FILE_PATH = \"data/WF 3 F1-R12 - Great Britain.xlsx\"\n",
    "SHEET_NAME = \"Worksheet\"\n",
    "HEADER_ROW_INDEX = 5 \n",
    "MARKET_A = 'Italy'\n",
    "MARKET_B = 'Mexico'\n",
    "\n",
    "# Define the columns used for the TIGHT comparison (channels, duration, broadcaster)\n",
    "# *** CHANGE: 'Program Title' is explicitly removed from the CHECK_COLS ***\n",
    "CHECK_COLS = ['TV-Channel', 'Duration', 'Broadcaster'] \n",
    "SUMMARY_COLS = ['TV-Channel', 'Duration', 'Broadcaster'] # Columns to display in the summary table\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        FILE_PATH,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=HEADER_ROW_INDEX\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n❌ ERROR: File not found at the specified path: {FILE_PATH}\")\n",
    "    print(\"Please ensure the file exists and the path is correct before running locally.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 1. Prepare and Filter Data\n",
    "# Standardize key comparison columns to prevent type errors\n",
    "for col in CHECK_COLS:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Filter data for only the two target markets\n",
    "df_filtered = df[df['Market'].isin([MARKET_A, MARKET_B])].copy()\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(f\"\\nNo data found for markets {MARKET_A} or {MARKET_B}. Check spelling or data source.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# 2. Identify Matching Lines (Content Duplicates)\n",
    "# Find content lines (based on CHECK_COLS) that exist in BOTH markets\n",
    "duplicate_mask = df_filtered.duplicated(subset=CHECK_COLS, keep=False)\n",
    "matching_rows = df_filtered[duplicate_mask].copy()\n",
    "\n",
    "# A set of keys that exist in both Italy and Mexico (Cross-Market Matches)\n",
    "matching_keys = matching_rows.groupby(CHECK_COLS).filter(\n",
    "    lambda x: set(x['Market'].unique()) == {MARKET_A, MARKET_B}\n",
    ")\n",
    "\n",
    "# 3. Calculate Summary Statistics\n",
    "# Note: total_matched_lines is based on unique content keys, divided by 2 because each match is counted twice\n",
    "total_matched_lines = matching_keys.drop_duplicates(subset=CHECK_COLS).shape[0]\n",
    "total_rows_A = df_filtered[df_filtered['Market'] == MARKET_A].shape[0]\n",
    "total_rows_B = df_filtered[df_filtered['Market'] == MARKET_B].shape[0]\n",
    "\n",
    "# Rows that are unique to each market (not matched content)\n",
    "unmatched_rows_A = total_rows_A - matching_keys[matching_keys['Market'] == MARKET_A].drop_duplicates(subset=CHECK_COLS).shape[0]\n",
    "unmatched_rows_B = total_rows_B - matching_keys[matching_keys['Market'] == MARKET_B].drop_duplicates(subset=CHECK_COLS).shape[0]\n",
    "\n",
    "\n",
    "# 4. Display Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"                       MARKET COMPARISON: {MARKET_A.upper()} vs {MARKET_B.upper()}                   \")\n",
    "print(\"================================================================================\")\n",
    "print(f\"**COMPARISON CRITERIA (MATCHING):** '{', '.join(CHECK_COLS)}'.\")\n",
    "print(f\"Total rows in {MARKET_A}: {total_rows_A}\")\n",
    "print(f\"Total rows in {MARKET_B}: {total_rows_B}\")\n",
    "print(\"================================================================================\")\n",
    "\n",
    "print(\"\\n--- MATCHING CONTENT SUMMARY ---\")\n",
    "print(f\"✅ **Total unique content lines matching in BOTH markets:** {total_matched_lines}\")\n",
    "\n",
    "# List the key details for the matched content\n",
    "matched_content_df = matching_keys.drop_duplicates(subset=CHECK_COLS).head(10).copy()\n",
    "matched_content_df['Status'] = 'MATCHED'\n",
    "print(\"\\nFirst 10 Matched Content Lines:\")\n",
    "print(matched_content_df[['Status'] + SUMMARY_COLS].to_markdown(index=False))\n",
    "\n",
    "print(\"\\n--- UNMATCHED CONTENT SUMMARY ---\")\n",
    "print(f\"❌ **Unique content lines found ONLY in {MARKET_A}:** {unmatched_rows_A}\")\n",
    "print(f\"❌ **Unique content lines found ONLY in {MARKET_B}:** {unmatched_rows_B}\")\n",
    "\n",
    "# Display the unmatched rows for Italy (up to 5)\n",
    "unmatched_A_df = df_filtered.groupby(CHECK_COLS).filter(lambda x: MARKET_A in x['Market'].values and MARKET_B not in x['Market'].values)\n",
    "print(f\"\\nFirst 5 unique lines found ONLY in {MARKET_A}:\")\n",
    "print(unmatched_A_df.drop_duplicates(subset=CHECK_COLS).head(5)[SUMMARY_COLS + ['Program Title']].to_markdown(index=False))\n",
    "\n",
    "# Display the unmatched rows for Mexico (up to 5)\n",
    "unmatched_B_df = df_filtered.groupby(CHECK_COLS).filter(lambda x: MARKET_B in x['Market'].values and MARKET_A not in x['Market'].values)\n",
    "print(f\"\\nFirst 5 unique lines found ONLY in {MARKET_B}:\")\n",
    "print(unmatched_B_df.drop_duplicates(subset=CHECK_COLS).head(5)[SUMMARY_COLS + ['Program Title']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d10b4-4b00-45e7-a39a-641bccd5e6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
